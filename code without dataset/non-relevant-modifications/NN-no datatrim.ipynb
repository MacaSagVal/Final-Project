{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a5a3c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:24:08.748971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 12:24:08.843481: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-15 12:24:08.845923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:08.845932: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-15 12:24:09.256008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:09.256066: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:09.256070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maca/anaconda3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # used for handling numbers\n",
    "import pandas as pd # used for handling the dataset\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e94e918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494020, 42)\n",
      "(494020, 2)\n"
     ]
    }
   ],
   "source": [
    "#reading the dataset\n",
    "df = pd.read_csv('10_data_trimed_attack_noAttack.csv')\n",
    "\n",
    "def read_dataset():\n",
    "    #print\n",
    "    X = df[df.columns[0:42]].values\n",
    "    y = df[df.columns[41]]\n",
    "    \n",
    "    \n",
    "    #encode the dependant variable\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    return(X,Y)\n",
    "\n",
    "#define one-hot-encoder function\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    "\n",
    "#Read the dataset\n",
    "X, Y = read_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b157746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395216, 42)\n",
      "(395216, 2)\n",
      "(98804, 42)\n",
      "(98804, 2)\n"
     ]
    }
   ],
   "source": [
    "#shufffle the dataset to mix up the rows\n",
    "X,Y = shuffle(X, Y,random_state = 1)\n",
    "\n",
    "#dataset into train & test \n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.20, random_state=415)\n",
    "\n",
    "#shapes of the training and testing\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cffbc314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_dim 42\n"
     ]
    }
   ],
   "source": [
    "#define the important parameters and variables to work with the tensors\n",
    "learning_rate = 0.4\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2\n",
    "model_path = \"model\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "969f8a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 20\n",
    "n_hidden_2 = 20\n",
    "n_hidden_3 = 20\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01da034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "\n",
    "def attack_finder(x, weights, biases):\n",
    "    \n",
    "    #RELU activation function\n",
    "    layer_1 = tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #sigmoid activation function\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights[\"h2\"]), biases[\"b2\"])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "     \n",
    "    #softmax activation function\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights[\"h3\"]), biases[\"b3\"])\n",
    "    layer_3 = tf.nn.softmax(layer_3)\n",
    "    \n",
    "    #outer layer relu activation function\n",
    "    out_layer = tf.add(tf.matmul(layer_3, weights[\"out\"]), biases[\"out\"])\n",
    "    out_layer = tf.nn.softmax(out_layer)\n",
    "    \n",
    "    return out_layer\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b981384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the weights and biases for each layer\n",
    "\n",
    "weights = {\n",
    "    \"h1\" : tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    \"h2\" : tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    \"h3\" : tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    \"out\" : tf.Variable(tf.truncated_normal([n_hidden_3, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    \"b1\" : tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    \"b2\" : tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    \"b3\" : tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    \"out\" : tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f959307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all the variables\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ec6215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "#call your model defined\n",
    "y = attack_finder(x, weights, biases)\n",
    "\n",
    "print(y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a27205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "#training_step = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea49205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 12:24:10.525313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-15 12:24:10.525432: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525534: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-15 12:24:10.525603: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-15 12:24:10.526110: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 12:24:10.528152: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:357] MLIR V1 optimization pass is not enabled\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2eb697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0 - cost:  0.5214029 - MSE:  0.15776696296698817 - train Accuracy:  0.8033961\n",
      "epoch :  1 - cost:  0.51998764 - MSE:  0.15778381782362097 - train Accuracy:  0.8033961\n",
      "epoch :  2 - cost:  0.51868135 - MSE:  0.15780534570955537 - train Accuracy:  0.8033961\n",
      "epoch :  3 - cost:  0.51756436 - MSE:  0.1578475729869773 - train Accuracy:  0.8033961\n",
      "epoch :  4 - cost:  0.51646507 - MSE:  0.1578867772891467 - train Accuracy:  0.8033961\n",
      "epoch :  5 - cost:  0.5154865 - MSE:  0.15791964303164358 - train Accuracy:  0.8033961\n",
      "epoch :  6 - cost:  0.5146182 - MSE:  0.15796240838359968 - train Accuracy:  0.8033961\n",
      "epoch :  7 - cost:  0.5137662 - MSE:  0.1579921014810987 - train Accuracy:  0.8033961\n",
      "epoch :  8 - cost:  0.51294327 - MSE:  0.15801989153668808 - train Accuracy:  0.8033961\n",
      "epoch :  9 - cost:  0.5121948 - MSE:  0.15802976747842085 - train Accuracy:  0.8033961\n",
      "epoch :  10 - cost:  0.51148254 - MSE:  0.15802885656307303 - train Accuracy:  0.8033961\n",
      "epoch :  11 - cost:  0.510846 - MSE:  0.1580275877991404 - train Accuracy:  0.8033961\n",
      "epoch :  12 - cost:  0.51017475 - MSE:  0.15800835950207456 - train Accuracy:  0.8033961\n",
      "epoch :  13 - cost:  0.5096018 - MSE:  0.15799049428052206 - train Accuracy:  0.8033961\n",
      "epoch :  14 - cost:  0.50901866 - MSE:  0.15796082832641187 - train Accuracy:  0.8033961\n",
      "epoch :  15 - cost:  0.50842303 - MSE:  0.15791158097674796 - train Accuracy:  0.8033961\n",
      "epoch :  16 - cost:  0.50790966 - MSE:  0.1578538798549244 - train Accuracy:  0.8033961\n",
      "epoch :  17 - cost:  0.50735486 - MSE:  0.1577799592083399 - train Accuracy:  0.8033961\n",
      "epoch :  18 - cost:  0.5068781 - MSE:  0.15770936848580386 - train Accuracy:  0.8033961\n",
      "epoch :  19 - cost:  0.50638634 - MSE:  0.15762749261573938 - train Accuracy:  0.8033961\n",
      "epoch :  20 - cost:  0.5058746 - MSE:  0.15752641989998328 - train Accuracy:  0.8033961\n",
      "epoch :  21 - cost:  0.5054526 - MSE:  0.15748294695632387 - train Accuracy:  0.8033961\n",
      "epoch :  22 - cost:  0.5049946 - MSE:  0.15735900237220157 - train Accuracy:  0.8033961\n",
      "epoch :  23 - cost:  0.50454336 - MSE:  0.157224241085621 - train Accuracy:  0.8033961\n",
      "epoch :  24 - cost:  0.5041023 - MSE:  0.1570746321973439 - train Accuracy:  0.8033961\n",
      "epoch :  25 - cost:  0.50366414 - MSE:  0.15691512636200844 - train Accuracy:  0.8033961\n",
      "epoch :  26 - cost:  0.5032335 - MSE:  0.15674670709958594 - train Accuracy:  0.8033961\n",
      "epoch :  27 - cost:  0.502807 - MSE:  0.15656306801961936 - train Accuracy:  0.8033961\n",
      "epoch :  28 - cost:  0.502383 - MSE:  0.15635965075755437 - train Accuracy:  0.8033961\n",
      "epoch :  29 - cost:  0.50195885 - MSE:  0.15614022932569915 - train Accuracy:  0.8033961\n",
      "epoch :  30 - cost:  0.5015353 - MSE:  0.15590598653350315 - train Accuracy:  0.8033961\n",
      "epoch :  31 - cost:  0.50117046 - MSE:  0.1556696362115053 - train Accuracy:  0.8033961\n",
      "epoch :  32 - cost:  0.50070184 - MSE:  0.15541498583461966 - train Accuracy:  0.8033961\n",
      "epoch :  33 - cost:  0.50033754 - MSE:  0.15514726841159535 - train Accuracy:  0.8033961\n",
      "epoch :  34 - cost:  0.49989554 - MSE:  0.15486901179797294 - train Accuracy:  0.8033961\n",
      "epoch :  35 - cost:  0.49954334 - MSE:  0.1545909472962178 - train Accuracy:  0.8033961\n",
      "epoch :  36 - cost:  0.4991309 - MSE:  0.15428853393516018 - train Accuracy:  0.8033961\n",
      "epoch :  37 - cost:  0.49871558 - MSE:  0.15396379060106327 - train Accuracy:  0.8033961\n",
      "epoch :  38 - cost:  0.49823728 - MSE:  0.1536286321002642 - train Accuracy:  0.8033961\n",
      "epoch :  39 - cost:  0.4978717 - MSE:  0.1532813341963565 - train Accuracy:  0.8033961\n",
      "epoch :  40 - cost:  0.4974457 - MSE:  0.15291041225672108 - train Accuracy:  0.8033961\n",
      "epoch :  41 - cost:  0.49700734 - MSE:  0.15252450706887336 - train Accuracy:  0.8033961\n",
      "epoch :  42 - cost:  0.49650258 - MSE:  0.1521044885200704 - train Accuracy:  0.8033961\n",
      "epoch :  43 - cost:  0.49612436 - MSE:  0.15167967329589338 - train Accuracy:  0.8033961\n",
      "epoch :  44 - cost:  0.4956658 - MSE:  0.1512165461091888 - train Accuracy:  0.8033961\n",
      "epoch :  45 - cost:  0.4951312 - MSE:  0.15074220314033182 - train Accuracy:  0.8033961\n",
      "epoch :  46 - cost:  0.49472386 - MSE:  0.15024036270267327 - train Accuracy:  0.8033961\n",
      "epoch :  47 - cost:  0.49424317 - MSE:  0.1497128098688249 - train Accuracy:  0.8033961\n",
      "epoch :  48 - cost:  0.49374393 - MSE:  0.1491739986225618 - train Accuracy:  0.8033961\n",
      "epoch :  49 - cost:  0.4931586 - MSE:  0.14859161436638638 - train Accuracy:  0.8033961\n",
      "epoch :  50 - cost:  0.4927142 - MSE:  0.14799139651111198 - train Accuracy:  0.8033961\n",
      "epoch :  51 - cost:  0.4921921 - MSE:  0.14737803610967043 - train Accuracy:  0.8033961\n",
      "epoch :  52 - cost:  0.49163684 - MSE:  0.14671364192836955 - train Accuracy:  0.8033961\n",
      "epoch :  53 - cost:  0.4910626 - MSE:  0.14603943640458947 - train Accuracy:  0.8033961\n",
      "epoch :  54 - cost:  0.4904902 - MSE:  0.1453023710430765 - train Accuracy:  0.8033961\n",
      "epoch :  55 - cost:  0.48982155 - MSE:  0.14461698243582813 - train Accuracy:  0.8033961\n",
      "epoch :  56 - cost:  0.48917815 - MSE:  0.14384541292359018 - train Accuracy:  0.8033961\n",
      "epoch :  57 - cost:  0.48851937 - MSE:  0.14300445438258855 - train Accuracy:  0.8033961\n",
      "epoch :  58 - cost:  0.48800138 - MSE:  0.14218621694154737 - train Accuracy:  0.8033961\n",
      "epoch :  59 - cost:  0.48733592 - MSE:  0.14131716961912824 - train Accuracy:  0.8033961\n",
      "epoch :  60 - cost:  0.48652738 - MSE:  0.14043601242405812 - train Accuracy:  0.8033961\n",
      "epoch :  61 - cost:  0.48577103 - MSE:  0.13946590156954744 - train Accuracy:  0.8033961\n",
      "epoch :  62 - cost:  0.48517263 - MSE:  0.1385165222068018 - train Accuracy:  0.8033961\n",
      "epoch :  63 - cost:  0.48428193 - MSE:  0.13752436296096993 - train Accuracy:  0.8033961\n",
      "epoch :  64 - cost:  0.48344845 - MSE:  0.1364297738973033 - train Accuracy:  0.8033961\n",
      "epoch :  65 - cost:  0.48260245 - MSE:  0.1352879333188758 - train Accuracy:  0.8033961\n",
      "epoch :  66 - cost:  0.48192832 - MSE:  0.13416462561186837 - train Accuracy:  0.8033961\n",
      "epoch :  67 - cost:  0.48085216 - MSE:  0.13294129077964378 - train Accuracy:  0.8033961\n",
      "epoch :  68 - cost:  0.48010108 - MSE:  0.13172806408551993 - train Accuracy:  0.8033961\n",
      "epoch :  69 - cost:  0.4789771 - MSE:  0.13042526540866375 - train Accuracy:  0.8033961\n",
      "epoch :  70 - cost:  0.4782061 - MSE:  0.1291319697411663 - train Accuracy:  0.8033961\n",
      "epoch :  71 - cost:  0.47697872 - MSE:  0.12773708052618665 - train Accuracy:  0.8033961\n",
      "epoch :  72 - cost:  0.47607666 - MSE:  0.1263245652034255 - train Accuracy:  0.8033961\n",
      "epoch :  73 - cost:  0.47516245 - MSE:  0.12531067949503186 - train Accuracy:  0.8033961\n",
      "epoch :  74 - cost:  0.47392735 - MSE:  0.12361961096503658 - train Accuracy:  0.8033961\n",
      "epoch :  75 - cost:  0.47261122 - MSE:  0.12183034918427228 - train Accuracy:  0.8033961\n",
      "epoch :  76 - cost:  0.47120342 - MSE:  0.1199856376319056 - train Accuracy:  0.8033961\n",
      "epoch :  77 - cost:  0.4697916 - MSE:  0.11811535254967355 - train Accuracy:  0.8033961\n",
      "epoch :  78 - cost:  0.46833953 - MSE:  0.11619979151070314 - train Accuracy:  0.8033961\n",
      "epoch :  79 - cost:  0.46765575 - MSE:  0.11521026387425634 - train Accuracy:  0.8033961\n",
      "epoch :  80 - cost:  0.46616554 - MSE:  0.11327821921851616 - train Accuracy:  0.8033961\n",
      "epoch :  81 - cost:  0.4650031 - MSE:  0.1114057492071838 - train Accuracy:  0.8033961\n",
      "epoch :  82 - cost:  0.46319038 - MSE:  0.10936345580224222 - train Accuracy:  0.8033961\n",
      "epoch :  83 - cost:  0.46156082 - MSE:  0.1072444462389795 - train Accuracy:  0.8033961\n",
      "epoch :  84 - cost:  0.46021277 - MSE:  0.10521743913125954 - train Accuracy:  0.8033961\n",
      "epoch :  85 - cost:  0.45820573 - MSE:  0.10293355647758376 - train Accuracy:  0.8033961\n",
      "epoch :  86 - cost:  0.45665914 - MSE:  0.10062498342324895 - train Accuracy:  0.8033961\n",
      "epoch :  87 - cost:  0.45444292 - MSE:  0.0981210088868093 - train Accuracy:  0.8033961\n",
      "epoch :  88 - cost:  0.45293054 - MSE:  0.09578388786005891 - train Accuracy:  0.8033961\n",
      "epoch :  89 - cost:  0.45096213 - MSE:  0.09338908465929181 - train Accuracy:  0.8033961\n",
      "epoch :  90 - cost:  0.44883355 - MSE:  0.0908019067707136 - train Accuracy:  0.8033961\n",
      "epoch :  91 - cost:  0.44671285 - MSE:  0.08827294684391598 - train Accuracy:  0.8033961\n",
      "epoch :  92 - cost:  0.44457224 - MSE:  0.08566094909989871 - train Accuracy:  0.8033961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  93 - cost:  0.44245064 - MSE:  0.08311309077736195 - train Accuracy:  0.8033961\n",
      "epoch :  94 - cost:  0.44015926 - MSE:  0.08033887808794629 - train Accuracy:  0.8045221\n",
      "epoch :  95 - cost:  0.43721163 - MSE:  0.07690482250407889 - train Accuracy:  0.8047903\n",
      "epoch :  96 - cost:  0.4342061 - MSE:  0.0736780657588765 - train Accuracy:  0.8050914\n",
      "epoch :  97 - cost:  0.43069604 - MSE:  0.0697442267955609 - train Accuracy:  0.82023245\n",
      "epoch :  98 - cost:  0.42885298 - MSE:  0.06774690430758637 - train Accuracy:  0.87462044\n",
      "epoch :  99 - cost:  0.42704484 - MSE:  0.06580288745484458 - train Accuracy:  0.8930686\n",
      "epoch :  100 - cost:  0.42526522 - MSE:  0.06389930922197726 - train Accuracy:  0.9007454\n",
      "epoch :  101 - cost:  0.4235168 - MSE:  0.062059656223957316 - train Accuracy:  0.90452814\n",
      "epoch :  102 - cost:  0.42178804 - MSE:  0.06025671770807953 - train Accuracy:  0.9063423\n",
      "epoch :  103 - cost:  0.42007843 - MSE:  0.0584971535739891 - train Accuracy:  0.9065726\n",
      "epoch :  104 - cost:  0.41838127 - MSE:  0.056768488516209796 - train Accuracy:  0.92044854\n",
      "epoch :  105 - cost:  0.41669086 - MSE:  0.055074800221649574 - train Accuracy:  0.92146826\n",
      "epoch :  106 - cost:  0.41500565 - MSE:  0.053404400691727034 - train Accuracy:  0.9274498\n",
      "epoch :  107 - cost:  0.41338965 - MSE:  0.051821886904681265 - train Accuracy:  0.92724484\n",
      "epoch :  108 - cost:  0.41180456 - MSE:  0.05029875296788767 - train Accuracy:  0.9274599\n",
      "epoch :  109 - cost:  0.4102369 - MSE:  0.04880766626960214 - train Accuracy:  0.93103516\n",
      "epoch :  110 - cost:  0.40869984 - MSE:  0.04736224524526462 - train Accuracy:  0.9318322\n",
      "epoch :  111 - cost:  0.40719578 - MSE:  0.04597260816844446 - train Accuracy:  0.932237\n",
      "epoch :  112 - cost:  0.40564275 - MSE:  0.04453546503399679 - train Accuracy:  0.93253815\n",
      "epoch :  113 - cost:  0.40404373 - MSE:  0.0430902627497105 - train Accuracy:  0.9529776\n",
      "epoch :  114 - cost:  0.4026471 - MSE:  0.041864537557197934 - train Accuracy:  0.9566161\n",
      "epoch :  115 - cost:  0.40128443 - MSE:  0.04069156969704924 - train Accuracy:  0.95681095\n",
      "epoch :  116 - cost:  0.3999553 - MSE:  0.03956642809312909 - train Accuracy:  0.9569223\n",
      "epoch :  117 - cost:  0.39866012 - MSE:  0.038491568277940674 - train Accuracy:  0.9736296\n",
      "epoch :  118 - cost:  0.3973946 - MSE:  0.03746366908427557 - train Accuracy:  0.97532994\n",
      "epoch :  119 - cost:  0.39615887 - MSE:  0.036474462399012246 - train Accuracy:  0.9754033\n",
      "epoch :  120 - cost:  0.39494607 - MSE:  0.03552477852236729 - train Accuracy:  0.9755703\n",
      "epoch :  121 - cost:  0.3937714 - MSE:  0.03462017066814579 - train Accuracy:  0.97568923\n",
      "epoch :  122 - cost:  0.3926222 - MSE:  0.03375372030806551 - train Accuracy:  0.9758158\n",
      "epoch :  123 - cost:  0.39149928 - MSE:  0.03292748049494202 - train Accuracy:  0.9779791\n",
      "epoch :  124 - cost:  0.39040452 - MSE:  0.03213512115318965 - train Accuracy:  0.98247796\n",
      "epoch :  125 - cost:  0.38933307 - MSE:  0.03137002724677327 - train Accuracy:  0.98239446\n",
      "epoch :  126 - cost:  0.38827273 - MSE:  0.0306238625601603 - train Accuracy:  0.9851094\n",
      "epoch :  127 - cost:  0.38708106 - MSE:  0.029765050646335178 - train Accuracy:  0.9851069\n",
      "epoch :  128 - cost:  0.38609326 - MSE:  0.029115542129531078 - train Accuracy:  0.9851069\n",
      "epoch :  129 - cost:  0.38512507 - MSE:  0.02848570589514226 - train Accuracy:  0.98516256\n",
      "epoch :  130 - cost:  0.38418627 - MSE:  0.027888492238738117 - train Accuracy:  0.98516506\n",
      "epoch :  131 - cost:  0.38326082 - MSE:  0.027306490006996913 - train Accuracy:  0.9851701\n",
      "epoch :  132 - cost:  0.38235614 - MSE:  0.02674220150631965 - train Accuracy:  0.9851878\n",
      "epoch :  133 - cost:  0.38148558 - MSE:  0.026212222354830672 - train Accuracy:  0.9851929\n",
      "epoch :  134 - cost:  0.38063556 - MSE:  0.025705828174020513 - train Accuracy:  0.98559266\n",
      "epoch :  135 - cost:  0.3798101 - MSE:  0.025223573559411155 - train Accuracy:  0.9856003\n",
      "epoch :  136 - cost:  0.37900466 - MSE:  0.02475967067295544 - train Accuracy:  0.9856028\n",
      "epoch :  137 - cost:  0.37821886 - MSE:  0.024317236403667737 - train Accuracy:  0.98560786\n",
      "epoch :  138 - cost:  0.37745258 - MSE:  0.02389314412070584 - train Accuracy:  0.98560786\n",
      "epoch :  139 - cost:  0.3767036 - MSE:  0.02348492138530193 - train Accuracy:  0.9856104\n",
      "epoch :  140 - cost:  0.37596896 - MSE:  0.023086375443173202 - train Accuracy:  0.98562306\n",
      "epoch :  141 - cost:  0.3752506 - MSE:  0.02270065225076589 - train Accuracy:  0.98563063\n",
      "epoch :  142 - cost:  0.37453428 - MSE:  0.02231137681007086 - train Accuracy:  0.9857344\n",
      "epoch :  143 - cost:  0.3738468 - MSE:  0.021957244334495564 - train Accuracy:  0.98573947\n",
      "epoch :  144 - cost:  0.37317806 - MSE:  0.021618983691770018 - train Accuracy:  0.98593175\n",
      "epoch :  145 - cost:  0.37252563 - MSE:  0.02129628640194972 - train Accuracy:  0.9859393\n",
      "epoch :  146 - cost:  0.37188518 - MSE:  0.020983894276487468 - train Accuracy:  0.9859419\n",
      "epoch :  147 - cost:  0.37126103 - MSE:  0.020682080251229907 - train Accuracy:  0.985957\n",
      "epoch :  148 - cost:  0.3706479 - MSE:  0.02039471773203998 - train Accuracy:  0.9859596\n",
      "epoch :  149 - cost:  0.37004736 - MSE:  0.020105305793745594 - train Accuracy:  0.98596466\n",
      "epoch :  150 - cost:  0.36945826 - MSE:  0.019829592835489438 - train Accuracy:  0.9859621\n",
      "epoch :  151 - cost:  0.36888325 - MSE:  0.01957223065994543 - train Accuracy:  0.9859798\n",
      "epoch :  152 - cost:  0.36837652 - MSE:  0.01933509666466904 - train Accuracy:  0.98594695\n",
      "epoch :  153 - cost:  0.36783162 - MSE:  0.0190966789578335 - train Accuracy:  0.98594946\n",
      "epoch :  154 - cost:  0.36729714 - MSE:  0.018864215406580766 - train Accuracy:  0.9874676\n",
      "epoch :  155 - cost:  0.3667697 - MSE:  0.018632136672956316 - train Accuracy:  0.98747015\n",
      "epoch :  156 - cost:  0.3662562 - MSE:  0.018412766643159297 - train Accuracy:  0.9874752\n",
      "epoch :  157 - cost:  0.3657565 - MSE:  0.01820483799417762 - train Accuracy:  0.9874803\n",
      "epoch :  158 - cost:  0.36526066 - MSE:  0.017997764215517676 - train Accuracy:  0.98748785\n",
      "epoch :  159 - cost:  0.36477318 - MSE:  0.01779235565501491 - train Accuracy:  0.98748535\n",
      "epoch :  160 - cost:  0.36428672 - MSE:  0.017606285325226192 - train Accuracy:  0.98748785\n",
      "epoch :  161 - cost:  0.36379984 - MSE:  0.017409253988886063 - train Accuracy:  0.98748785\n",
      "epoch :  162 - cost:  0.3633918 - MSE:  0.01728571054901575 - train Accuracy:  0.98748785\n",
      "epoch :  163 - cost:  0.3629573 - MSE:  0.017123620260818963 - train Accuracy:  0.98749036\n",
      "epoch :  164 - cost:  0.36253372 - MSE:  0.016965967546322964 - train Accuracy:  0.98749036\n",
      "epoch :  165 - cost:  0.3621168 - MSE:  0.0168119854932886 - train Accuracy:  0.98749036\n",
      "epoch :  166 - cost:  0.36169598 - MSE:  0.01664959595841241 - train Accuracy:  0.9874954\n",
      "epoch :  167 - cost:  0.36129227 - MSE:  0.0164980025688607 - train Accuracy:  0.9875005\n",
      "epoch :  168 - cost:  0.36090317 - MSE:  0.016361406924335218 - train Accuracy:  0.98750305\n",
      "epoch :  169 - cost:  0.36053053 - MSE:  0.016223698959072882 - train Accuracy:  0.98750556\n",
      "epoch :  170 - cost:  0.3601454 - MSE:  0.01608501321175659 - train Accuracy:  0.9875106\n",
      "epoch :  171 - cost:  0.3597728 - MSE:  0.015964271703165403 - train Accuracy:  0.9875106\n",
      "epoch :  172 - cost:  0.35941276 - MSE:  0.01583260868697447 - train Accuracy:  0.9875132\n",
      "epoch :  173 - cost:  0.3590485 - MSE:  0.01571063423658254 - train Accuracy:  0.98752075\n",
      "epoch :  174 - cost:  0.35873392 - MSE:  0.015642556935239103 - train Accuracy:  0.98752075\n",
      "epoch :  175 - cost:  0.3583867 - MSE:  0.015525330668285214 - train Accuracy:  0.9875283\n",
      "epoch :  176 - cost:  0.35804734 - MSE:  0.015414931465175927 - train Accuracy:  0.9875283\n",
      "epoch :  177 - cost:  0.35770112 - MSE:  0.015294222985979404 - train Accuracy:  0.9875309\n",
      "epoch :  178 - cost:  0.35737112 - MSE:  0.015185122953473525 - train Accuracy:  0.9875334\n",
      "epoch :  179 - cost:  0.35704553 - MSE:  0.01507076602926593 - train Accuracy:  0.987541\n",
      "epoch :  180 - cost:  0.35678172 - MSE:  0.015041827582685767 - train Accuracy:  0.987546\n",
      "epoch :  181 - cost:  0.3564696 - MSE:  0.01494627647670883 - train Accuracy:  0.987541\n",
      "epoch :  182 - cost:  0.35616034 - MSE:  0.014858492370869104 - train Accuracy:  0.987546\n",
      "epoch :  183 - cost:  0.3558616 - MSE:  0.014768412692795429 - train Accuracy:  0.987546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  184 - cost:  0.35557178 - MSE:  0.014683381955504246 - train Accuracy:  0.9875435\n",
      "epoch :  185 - cost:  0.35528642 - MSE:  0.014604200702069777 - train Accuracy:  0.987546\n",
      "epoch :  186 - cost:  0.35500556 - MSE:  0.01452024130094097 - train Accuracy:  0.9875511\n",
      "epoch :  187 - cost:  0.35472804 - MSE:  0.014442157423101206 - train Accuracy:  0.9875486\n",
      "epoch :  188 - cost:  0.35445258 - MSE:  0.01436411793814462 - train Accuracy:  0.9875435\n",
      "epoch :  189 - cost:  0.3541779 - MSE:  0.014287280720247122 - train Accuracy:  0.98755366\n",
      "epoch :  190 - cost:  0.3539116 - MSE:  0.014213529244360168 - train Accuracy:  0.9875511\n",
      "epoch :  191 - cost:  0.35365084 - MSE:  0.014141558298460564 - train Accuracy:  0.9875511\n",
      "epoch :  192 - cost:  0.35339248 - MSE:  0.014067329048061846 - train Accuracy:  0.98755366\n",
      "epoch :  193 - cost:  0.3531357 - MSE:  0.013996510965364764 - train Accuracy:  0.98755366\n",
      "epoch :  194 - cost:  0.35288337 - MSE:  0.013927558941732953 - train Accuracy:  0.98755616\n",
      "epoch :  195 - cost:  0.35262758 - MSE:  0.013852545234945036 - train Accuracy:  0.98755366\n",
      "epoch :  196 - cost:  0.35237622 - MSE:  0.013779212625801297 - train Accuracy:  0.9875587\n",
      "epoch :  197 - cost:  0.3521444 - MSE:  0.013711724372850485 - train Accuracy:  0.9875587\n",
      "epoch :  198 - cost:  0.35192856 - MSE:  0.013691842118502207 - train Accuracy:  0.9875587\n",
      "epoch :  199 - cost:  0.351693 - MSE:  0.013635583099400465 - train Accuracy:  0.98755616\n",
      "epoch :  200 - cost:  0.35146043 - MSE:  0.013568467858302005 - train Accuracy:  0.9875612\n",
      "epoch :  201 - cost:  0.3512285 - MSE:  0.013508979303575365 - train Accuracy:  0.9875638\n",
      "epoch :  202 - cost:  0.35099164 - MSE:  0.013442092614335387 - train Accuracy:  0.9875663\n",
      "epoch :  203 - cost:  0.35075444 - MSE:  0.013366431991767964 - train Accuracy:  0.9875638\n",
      "epoch :  204 - cost:  0.3505343 - MSE:  0.01329829693466698 - train Accuracy:  0.9875612\n",
      "epoch :  205 - cost:  0.35031396 - MSE:  0.013251305887178443 - train Accuracy:  0.9875587\n",
      "epoch :  206 - cost:  0.35009322 - MSE:  0.01319190769264325 - train Accuracy:  0.9875638\n",
      "epoch :  207 - cost:  0.3498837 - MSE:  0.01316145434150078 - train Accuracy:  0.9875612\n",
      "epoch :  208 - cost:  0.34965754 - MSE:  0.01309062193974921 - train Accuracy:  0.9875587\n",
      "epoch :  209 - cost:  0.34945223 - MSE:  0.01303305007603837 - train Accuracy:  0.9875638\n",
      "epoch :  210 - cost:  0.34925526 - MSE:  0.013008035096118772 - train Accuracy:  0.9875638\n",
      "epoch :  211 - cost:  0.3490633 - MSE:  0.01289328497606332 - train Accuracy:  0.9877181\n",
      "epoch :  212 - cost:  0.3488404 - MSE:  0.012862741522824695 - train Accuracy:  0.9876422\n",
      "epoch :  213 - cost:  0.3486954 - MSE:  0.012889137111450915 - train Accuracy:  0.9875638\n",
      "epoch :  214 - cost:  0.34850246 - MSE:  0.012836226715087414 - train Accuracy:  0.9875638\n",
      "epoch :  215 - cost:  0.34831664 - MSE:  0.012802849653159585 - train Accuracy:  0.98757136\n",
      "epoch :  216 - cost:  0.34813076 - MSE:  0.012747749560393038 - train Accuracy:  0.9875663\n",
      "epoch :  217 - cost:  0.34795976 - MSE:  0.012742008343528042 - train Accuracy:  0.9875789\n",
      "epoch :  218 - cost:  0.3477576 - MSE:  0.012682823011977564 - train Accuracy:  0.98757136\n",
      "epoch :  219 - cost:  0.34756812 - MSE:  0.012628674841960725 - train Accuracy:  0.98757136\n",
      "epoch :  220 - cost:  0.34741902 - MSE:  0.012637375775165145 - train Accuracy:  0.9875764\n",
      "epoch :  221 - cost:  0.34724292 - MSE:  0.012589650195053386 - train Accuracy:  0.9875688\n",
      "epoch :  222 - cost:  0.34706268 - MSE:  0.012543831354154503 - train Accuracy:  0.9875815\n",
      "epoch :  223 - cost:  0.34688756 - MSE:  0.012502471509721006 - train Accuracy:  0.9875789\n",
      "epoch :  224 - cost:  0.34671554 - MSE:  0.012454420337767244 - train Accuracy:  0.987584\n",
      "epoch :  225 - cost:  0.34656143 - MSE:  0.012431795245121408 - train Accuracy:  0.9875815\n",
      "epoch :  226 - cost:  0.34640667 - MSE:  0.012405357196937864 - train Accuracy:  0.987584\n",
      "epoch :  227 - cost:  0.34622982 - MSE:  0.012356895569601806 - train Accuracy:  0.987584\n",
      "epoch :  228 - cost:  0.3460742 - MSE:  0.012327471826174862 - train Accuracy:  0.987584\n",
      "epoch :  229 - cost:  0.3459306 - MSE:  0.012314374059768998 - train Accuracy:  0.9875941\n",
      "epoch :  230 - cost:  0.34577608 - MSE:  0.01228393433306982 - train Accuracy:  0.98760426\n",
      "epoch :  231 - cost:  0.34561157 - MSE:  0.012241085619341563 - train Accuracy:  0.9876169\n",
      "epoch :  232 - cost:  0.34540755 - MSE:  0.012189295265385963 - train Accuracy:  0.98765486\n",
      "epoch :  233 - cost:  0.34507972 - MSE:  0.01206182521399801 - train Accuracy:  0.9877839\n",
      "epoch :  234 - cost:  0.34512383 - MSE:  0.012089349849064655 - train Accuracy:  0.98808753\n",
      "epoch :  235 - cost:  0.34494492 - MSE:  0.012051442455375259 - train Accuracy:  0.98805463\n",
      "epoch :  236 - cost:  0.34467584 - MSE:  0.012041572767866571 - train Accuracy:  0.98774594\n",
      "epoch :  237 - cost:  0.34453803 - MSE:  0.012025961747642427 - train Accuracy:  0.9877839\n",
      "epoch :  238 - cost:  0.3444001 - MSE:  0.01199429059429296 - train Accuracy:  0.9878244\n",
      "epoch :  239 - cost:  0.34426606 - MSE:  0.011964886922030115 - train Accuracy:  0.9878269\n",
      "epoch :  240 - cost:  0.34413627 - MSE:  0.011933180227730657 - train Accuracy:  0.98782945\n",
      "epoch :  241 - cost:  0.344007 - MSE:  0.01192134002981698 - train Accuracy:  0.9877561\n",
      "epoch :  242 - cost:  0.3438743 - MSE:  0.011881894287957037 - train Accuracy:  0.98778135\n",
      "epoch :  243 - cost:  0.34375662 - MSE:  0.011881588876883507 - train Accuracy:  0.98779905\n",
      "epoch :  244 - cost:  0.3436312 - MSE:  0.011855152513334053 - train Accuracy:  0.98779655\n",
      "epoch :  245 - cost:  0.3435038 - MSE:  0.011826571919430899 - train Accuracy:  0.98779655\n",
      "epoch :  246 - cost:  0.34339848 - MSE:  0.011829041229212977 - train Accuracy:  0.9878067\n",
      "epoch :  247 - cost:  0.343274 - MSE:  0.011806938781646582 - train Accuracy:  0.9878168\n",
      "epoch :  248 - cost:  0.34315607 - MSE:  0.011788500489069742 - train Accuracy:  0.9878168\n",
      "epoch :  249 - cost:  0.34303698 - MSE:  0.011762699313019844 - train Accuracy:  0.9878193\n",
      "epoch :  250 - cost:  0.34292927 - MSE:  0.011763782245028458 - train Accuracy:  0.9878193\n",
      "epoch :  251 - cost:  0.34281674 - MSE:  0.01174346569474425 - train Accuracy:  0.9878244\n",
      "epoch :  252 - cost:  0.34270686 - MSE:  0.011734000810589904 - train Accuracy:  0.9878269\n",
      "epoch :  253 - cost:  0.34259984 - MSE:  0.011708650065341174 - train Accuracy:  0.98783195\n",
      "epoch :  254 - cost:  0.34248996 - MSE:  0.011695577666800388 - train Accuracy:  0.987837\n",
      "epoch :  255 - cost:  0.3423905 - MSE:  0.011698931891420955 - train Accuracy:  0.987837\n",
      "epoch :  256 - cost:  0.34228507 - MSE:  0.011683122541086846 - train Accuracy:  0.987837\n",
      "epoch :  257 - cost:  0.34217986 - MSE:  0.011668304780964903 - train Accuracy:  0.987837\n",
      "epoch :  258 - cost:  0.34207946 - MSE:  0.011656609503427572 - train Accuracy:  0.987837\n",
      "epoch :  259 - cost:  0.34197897 - MSE:  0.01164666347292417 - train Accuracy:  0.987837\n",
      "epoch :  260 - cost:  0.34188005 - MSE:  0.011635791701407243 - train Accuracy:  0.987837\n",
      "epoch :  261 - cost:  0.34178248 - MSE:  0.011624498354869239 - train Accuracy:  0.9878421\n",
      "epoch :  262 - cost:  0.3416854 - MSE:  0.011614223286044481 - train Accuracy:  0.9878396\n",
      "epoch :  263 - cost:  0.3415893 - MSE:  0.011602480069564733 - train Accuracy:  0.98784465\n",
      "epoch :  264 - cost:  0.34149396 - MSE:  0.011591031715281376 - train Accuracy:  0.98784715\n",
      "epoch :  265 - cost:  0.34139922 - MSE:  0.011578843885607447 - train Accuracy:  0.98784715\n",
      "epoch :  266 - cost:  0.34130633 - MSE:  0.011569521490268462 - train Accuracy:  0.9878522\n",
      "epoch :  267 - cost:  0.3412145 - MSE:  0.01155813050019744 - train Accuracy:  0.9878573\n",
      "epoch :  268 - cost:  0.34112343 - MSE:  0.011548487614755298 - train Accuracy:  0.9878573\n",
      "epoch :  269 - cost:  0.34103408 - MSE:  0.011539033190294845 - train Accuracy:  0.9878573\n",
      "epoch :  270 - cost:  0.340945 - MSE:  0.011529892254813297 - train Accuracy:  0.9878547\n",
      "epoch :  271 - cost:  0.34085748 - MSE:  0.011520649225457438 - train Accuracy:  0.9878573\n",
      "epoch :  272 - cost:  0.34077027 - MSE:  0.011512079376584614 - train Accuracy:  0.9878547\n",
      "epoch :  273 - cost:  0.34068507 - MSE:  0.01150287195464758 - train Accuracy:  0.9878573\n",
      "epoch :  274 - cost:  0.34059975 - MSE:  0.011494792448845192 - train Accuracy:  0.9878598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  275 - cost:  0.34051558 - MSE:  0.011486061896505839 - train Accuracy:  0.9878598\n",
      "epoch :  276 - cost:  0.34043258 - MSE:  0.011478205522638216 - train Accuracy:  0.98786235\n",
      "epoch :  277 - cost:  0.3403496 - MSE:  0.011469809290103395 - train Accuracy:  0.98786235\n",
      "epoch :  278 - cost:  0.34026828 - MSE:  0.011462469564619085 - train Accuracy:  0.98786235\n",
      "epoch :  279 - cost:  0.3401877 - MSE:  0.011454573366403554 - train Accuracy:  0.98786485\n",
      "epoch :  280 - cost:  0.34010834 - MSE:  0.011447573399775132 - train Accuracy:  0.98786485\n",
      "epoch :  281 - cost:  0.34002906 - MSE:  0.011439986384470765 - train Accuracy:  0.98786485\n",
      "epoch :  282 - cost:  0.33995125 - MSE:  0.011433147831422144 - train Accuracy:  0.98786485\n",
      "epoch :  283 - cost:  0.33987388 - MSE:  0.0114257941411397 - train Accuracy:  0.9878699\n",
      "epoch :  284 - cost:  0.33979717 - MSE:  0.011419021597028924 - train Accuracy:  0.9878699\n",
      "epoch :  285 - cost:  0.3397215 - MSE:  0.011411577649154264 - train Accuracy:  0.9878674\n",
      "epoch :  286 - cost:  0.3396462 - MSE:  0.011404867831981831 - train Accuracy:  0.9878699\n",
      "epoch :  287 - cost:  0.33957165 - MSE:  0.011397406865618265 - train Accuracy:  0.9878725\n",
      "epoch :  288 - cost:  0.33949825 - MSE:  0.011390891830090896 - train Accuracy:  0.987875\n",
      "epoch :  289 - cost:  0.33942482 - MSE:  0.011383956107233927 - train Accuracy:  0.9878775\n",
      "epoch :  290 - cost:  0.33935255 - MSE:  0.011377817793238825 - train Accuracy:  0.98788005\n",
      "epoch :  291 - cost:  0.339281 - MSE:  0.011371338202454055 - train Accuracy:  0.98788005\n",
      "epoch :  292 - cost:  0.33921054 - MSE:  0.011365737006616777 - train Accuracy:  0.9878775\n",
      "epoch :  293 - cost:  0.33913997 - MSE:  0.011359813200168727 - train Accuracy:  0.9878775\n",
      "epoch :  294 - cost:  0.33907068 - MSE:  0.011354605322162451 - train Accuracy:  0.98788005\n",
      "epoch :  295 - cost:  0.33900183 - MSE:  0.011349025965479211 - train Accuracy:  0.98788005\n",
      "epoch :  296 - cost:  0.3389339 - MSE:  0.01134425667591515 - train Accuracy:  0.98788005\n",
      "epoch :  297 - cost:  0.3388665 - MSE:  0.011338927266791352 - train Accuracy:  0.98788005\n",
      "epoch :  298 - cost:  0.33879915 - MSE:  0.011334523564380075 - train Accuracy:  0.9878775\n",
      "epoch :  299 - cost:  0.33873305 - MSE:  0.011329501810587644 - train Accuracy:  0.98788005\n",
      "epoch :  300 - cost:  0.3386677 - MSE:  0.011325418720198278 - train Accuracy:  0.9878775\n",
      "epoch :  301 - cost:  0.3386027 - MSE:  0.011320668042947582 - train Accuracy:  0.98788255\n",
      "epoch :  302 - cost:  0.33853865 - MSE:  0.011316911695100752 - train Accuracy:  0.9878775\n",
      "epoch :  303 - cost:  0.33847493 - MSE:  0.01131228180518101 - train Accuracy:  0.98788255\n",
      "epoch :  304 - cost:  0.33841154 - MSE:  0.011308689428129948 - train Accuracy:  0.98788255\n",
      "epoch :  305 - cost:  0.33834893 - MSE:  0.01130451563189053 - train Accuracy:  0.9878876\n",
      "epoch :  306 - cost:  0.3382877 - MSE:  0.011301014254616045 - train Accuracy:  0.9878876\n",
      "epoch :  307 - cost:  0.33822587 - MSE:  0.011296966689005494 - train Accuracy:  0.9878876\n",
      "epoch :  308 - cost:  0.33816528 - MSE:  0.011293658590242062 - train Accuracy:  0.9878902\n",
      "epoch :  309 - cost:  0.33810493 - MSE:  0.011289752074008015 - train Accuracy:  0.9878902\n",
      "epoch :  310 - cost:  0.33804497 - MSE:  0.011286778546702327 - train Accuracy:  0.9878902\n",
      "epoch :  311 - cost:  0.33798623 - MSE:  0.01128301586125239 - train Accuracy:  0.9878902\n",
      "epoch :  312 - cost:  0.3379271 - MSE:  0.011280285865692529 - train Accuracy:  0.9878902\n",
      "epoch :  313 - cost:  0.33786923 - MSE:  0.01127657930657215 - train Accuracy:  0.9878927\n",
      "epoch :  314 - cost:  0.33781156 - MSE:  0.011274043988011321 - train Accuracy:  0.9878902\n",
      "epoch :  315 - cost:  0.33775476 - MSE:  0.011270531028575143 - train Accuracy:  0.98789525\n",
      "epoch :  316 - cost:  0.3376979 - MSE:  0.011268116410082393 - train Accuracy:  0.98789525\n",
      "epoch :  317 - cost:  0.337642 - MSE:  0.01126474623830279 - train Accuracy:  0.98789525\n",
      "epoch :  318 - cost:  0.33758637 - MSE:  0.011262534728215774 - train Accuracy:  0.98789525\n",
      "epoch :  319 - cost:  0.33753142 - MSE:  0.011259241987804697 - train Accuracy:  0.98789525\n",
      "epoch :  320 - cost:  0.33747613 - MSE:  0.011257131432670688 - train Accuracy:  0.98789775\n",
      "epoch :  321 - cost:  0.33742225 - MSE:  0.01125408126331359 - train Accuracy:  0.98789775\n",
      "epoch :  322 - cost:  0.33736897 - MSE:  0.011252114857022615 - train Accuracy:  0.98789775\n",
      "epoch :  323 - cost:  0.3373157 - MSE:  0.011249128796685607 - train Accuracy:  0.98789775\n",
      "epoch :  324 - cost:  0.33726305 - MSE:  0.011247255358998232 - train Accuracy:  0.98789775\n",
      "epoch :  325 - cost:  0.33721063 - MSE:  0.01124409521156955 - train Accuracy:  0.98789775\n",
      "epoch :  326 - cost:  0.33715844 - MSE:  0.011240862872203909 - train Accuracy:  0.98789775\n",
      "epoch :  327 - cost:  0.337107 - MSE:  0.011239492362663785 - train Accuracy:  0.98789775\n",
      "epoch :  328 - cost:  0.3370567 - MSE:  0.011236697107787458 - train Accuracy:  0.98789775\n",
      "epoch :  329 - cost:  0.3370205 - MSE:  0.01125753693358757 - train Accuracy:  0.9879003\n",
      "epoch :  330 - cost:  0.33696216 - MSE:  0.01123759347635732 - train Accuracy:  0.9878927\n",
      "epoch :  331 - cost:  0.33690912 - MSE:  0.011233438670411449 - train Accuracy:  0.98789525\n",
      "epoch :  332 - cost:  0.3368582 - MSE:  0.011232552094251006 - train Accuracy:  0.98789775\n",
      "epoch :  333 - cost:  0.33680665 - MSE:  0.011232866870585119 - train Accuracy:  0.9879053\n",
      "epoch :  334 - cost:  0.33675742 - MSE:  0.011226123041291752 - train Accuracy:  0.9879079\n",
      "epoch :  335 - cost:  0.33670586 - MSE:  0.011220244658398427 - train Accuracy:  0.98791295\n",
      "epoch :  336 - cost:  0.33666143 - MSE:  0.011209859084738177 - train Accuracy:  0.9879028\n",
      "epoch :  337 - cost:  0.33662966 - MSE:  0.011236680823188482 - train Accuracy:  0.9879028\n",
      "epoch :  338 - cost:  0.33657342 - MSE:  0.01122525035336721 - train Accuracy:  0.9879104\n",
      "epoch :  339 - cost:  0.33652303 - MSE:  0.011215464719753274 - train Accuracy:  0.9879053\n",
      "epoch :  340 - cost:  0.33647507 - MSE:  0.01121165190307452 - train Accuracy:  0.98791295\n",
      "epoch :  341 - cost:  0.33643082 - MSE:  0.011216887404385206 - train Accuracy:  0.98791295\n",
      "epoch :  342 - cost:  0.33638424 - MSE:  0.011215391128786553 - train Accuracy:  0.98791546\n",
      "epoch :  343 - cost:  0.33633733 - MSE:  0.01121223994152173 - train Accuracy:  0.98791546\n",
      "epoch :  344 - cost:  0.33628824 - MSE:  0.011201058866595769 - train Accuracy:  0.987918\n",
      "epoch :  345 - cost:  0.33624604 - MSE:  0.011207623904310786 - train Accuracy:  0.9879205\n",
      "epoch :  346 - cost:  0.3362025 - MSE:  0.011208634738783781 - train Accuracy:  0.9879205\n",
      "epoch :  347 - cost:  0.33615834 - MSE:  0.011206762516049846 - train Accuracy:  0.9879205\n",
      "epoch :  348 - cost:  0.33611462 - MSE:  0.01120685498727282 - train Accuracy:  0.987918\n",
      "epoch :  349 - cost:  0.33606717 - MSE:  0.01119796095680975 - train Accuracy:  0.9879205\n",
      "epoch :  350 - cost:  0.33603257 - MSE:  0.011212197629702957 - train Accuracy:  0.9879205\n",
      "epoch :  351 - cost:  0.33598796 - MSE:  0.011208748454071993 - train Accuracy:  0.9879231\n",
      "epoch :  352 - cost:  0.33594558 - MSE:  0.011207698996188646 - train Accuracy:  0.9879231\n",
      "epoch :  353 - cost:  0.33590138 - MSE:  0.011202766180622643 - train Accuracy:  0.9879231\n",
      "epoch :  354 - cost:  0.33585992 - MSE:  0.01120284590805994 - train Accuracy:  0.9879231\n",
      "epoch :  355 - cost:  0.33581477 - MSE:  0.011194327844153945 - train Accuracy:  0.9879231\n",
      "epoch :  356 - cost:  0.33578172 - MSE:  0.011209170007410623 - train Accuracy:  0.9879231\n",
      "epoch :  357 - cost:  0.3357388 - MSE:  0.011205074465154535 - train Accuracy:  0.9879231\n",
      "epoch :  358 - cost:  0.33569735 - MSE:  0.011203539861559898 - train Accuracy:  0.9879231\n",
      "epoch :  359 - cost:  0.33565506 - MSE:  0.011193199480269382 - train Accuracy:  0.9879231\n",
      "epoch :  360 - cost:  0.33561638 - MSE:  0.011201335961103774 - train Accuracy:  0.9879231\n",
      "epoch :  361 - cost:  0.33557642 - MSE:  0.011200433832369912 - train Accuracy:  0.9879256\n",
      "epoch :  362 - cost:  0.33553696 - MSE:  0.011198871187717967 - train Accuracy:  0.9879256\n",
      "epoch :  363 - cost:  0.3354977 - MSE:  0.011201331840590639 - train Accuracy:  0.9879281\n",
      "epoch :  364 - cost:  0.33545485 - MSE:  0.01119138675604975 - train Accuracy:  0.9879281\n",
      "epoch :  365 - cost:  0.3354193 - MSE:  0.011197066239062957 - train Accuracy:  0.98793066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  366 - cost:  0.3353806 - MSE:  0.011199350203145208 - train Accuracy:  0.98793066\n",
      "epoch :  367 - cost:  0.33533654 - MSE:  0.01118685278006769 - train Accuracy:  0.98793066\n",
      "epoch :  368 - cost:  0.33737952 - MSE:  0.013145113674177701 - train Accuracy:  0.9857723\n",
      "epoch :  369 - cost:  0.33729288 - MSE:  0.013037927680148604 - train Accuracy:  0.98581535\n",
      "epoch :  370 - cost:  0.33723465 - MSE:  0.013024866912580202 - train Accuracy:  0.9858255\n",
      "epoch :  371 - cost:  0.33679673 - MSE:  0.012578884974941584 - train Accuracy:  0.9862708\n",
      "epoch :  372 - cost:  0.33521053 - MSE:  0.011058853764361299 - train Accuracy:  0.98793316\n",
      "epoch :  373 - cost:  0.33516115 - MSE:  0.011051350422822502 - train Accuracy:  0.9879585\n",
      "epoch :  374 - cost:  0.3351205 - MSE:  0.011048121779051744 - train Accuracy:  0.9879559\n",
      "epoch :  375 - cost:  0.33507925 - MSE:  0.011043496695340018 - train Accuracy:  0.9879559\n",
      "epoch :  376 - cost:  0.3350382 - MSE:  0.01103806148997178 - train Accuracy:  0.9879534\n",
      "epoch :  377 - cost:  0.33499995 - MSE:  0.0110280310398079 - train Accuracy:  0.9879559\n",
      "epoch :  378 - cost:  0.33495975 - MSE:  0.011009422885452995 - train Accuracy:  0.9879711\n",
      "epoch :  379 - cost:  0.33492193 - MSE:  0.011005427066109491 - train Accuracy:  0.9879737\n",
      "epoch :  380 - cost:  0.3348838 - MSE:  0.010995334207340406 - train Accuracy:  0.98798126\n",
      "epoch :  381 - cost:  0.33484766 - MSE:  0.010991689573304026 - train Accuracy:  0.98798376\n",
      "epoch :  382 - cost:  0.3348125 - MSE:  0.010993914523348067 - train Accuracy:  0.98798376\n",
      "epoch :  383 - cost:  0.3347765 - MSE:  0.010995818453873134 - train Accuracy:  0.98798376\n",
      "epoch :  384 - cost:  0.33474204 - MSE:  0.010997256172159645 - train Accuracy:  0.98798376\n",
      "epoch :  385 - cost:  0.33470735 - MSE:  0.01099837797053075 - train Accuracy:  0.98798376\n",
      "epoch :  386 - cost:  0.33467266 - MSE:  0.0109994225626586 - train Accuracy:  0.98798376\n",
      "epoch :  387 - cost:  0.3346393 - MSE:  0.011000341177352777 - train Accuracy:  0.98798376\n",
      "epoch :  388 - cost:  0.3346059 - MSE:  0.011001175282374306 - train Accuracy:  0.98798376\n",
      "epoch :  389 - cost:  0.3345721 - MSE:  0.011002074243522734 - train Accuracy:  0.98798376\n",
      "epoch :  390 - cost:  0.3345389 - MSE:  0.011003010764114493 - train Accuracy:  0.98798376\n",
      "epoch :  391 - cost:  0.3345054 - MSE:  0.01100391030434595 - train Accuracy:  0.98798376\n",
      "epoch :  392 - cost:  0.3344732 - MSE:  0.011004775598174374 - train Accuracy:  0.98798376\n",
      "epoch :  393 - cost:  0.33444077 - MSE:  0.011005544199216163 - train Accuracy:  0.9879863\n",
      "epoch :  394 - cost:  0.33440816 - MSE:  0.01100627432515047 - train Accuracy:  0.9879863\n",
      "epoch :  395 - cost:  0.33437636 - MSE:  0.011006875866455818 - train Accuracy:  0.9879863\n",
      "epoch :  396 - cost:  0.33434394 - MSE:  0.01100739454515071 - train Accuracy:  0.9879863\n",
      "epoch :  397 - cost:  0.33431256 - MSE:  0.011008135221175051 - train Accuracy:  0.9879863\n",
      "epoch :  398 - cost:  0.3342813 - MSE:  0.01100891210333314 - train Accuracy:  0.9879863\n",
      "epoch :  399 - cost:  0.3342506 - MSE:  0.01100964400179734 - train Accuracy:  0.9879863\n",
      "epoch :  400 - cost:  0.33421987 - MSE:  0.01101037272415042 - train Accuracy:  0.9879863\n",
      "epoch :  401 - cost:  0.33418876 - MSE:  0.011011069581150673 - train Accuracy:  0.9879863\n",
      "epoch :  402 - cost:  0.33415836 - MSE:  0.01101173086916282 - train Accuracy:  0.9879863\n",
      "epoch :  403 - cost:  0.33412853 - MSE:  0.011012365943354972 - train Accuracy:  0.9879863\n",
      "epoch :  404 - cost:  0.33409882 - MSE:  0.011012951172449945 - train Accuracy:  0.9879863\n",
      "epoch :  405 - cost:  0.3340685 - MSE:  0.011013444627142148 - train Accuracy:  0.9879863\n",
      "epoch :  406 - cost:  0.33403888 - MSE:  0.01101390144009777 - train Accuracy:  0.9879888\n",
      "epoch :  407 - cost:  0.33401003 - MSE:  0.01101430933152352 - train Accuracy:  0.9879863\n",
      "epoch :  408 - cost:  0.3339809 - MSE:  0.011014681670560736 - train Accuracy:  0.9879863\n",
      "epoch :  409 - cost:  0.3339519 - MSE:  0.011015029640459304 - train Accuracy:  0.9879863\n",
      "epoch :  410 - cost:  0.33392298 - MSE:  0.01101526291340837 - train Accuracy:  0.9879863\n",
      "epoch :  411 - cost:  0.33389363 - MSE:  0.011015305101893262 - train Accuracy:  0.9879863\n",
      "epoch :  412 - cost:  0.33386526 - MSE:  0.011015248116141206 - train Accuracy:  0.98798376\n",
      "epoch :  413 - cost:  0.3338369 - MSE:  0.01101510294153169 - train Accuracy:  0.98798376\n",
      "epoch :  414 - cost:  0.33380905 - MSE:  0.011014648852767822 - train Accuracy:  0.9879888\n",
      "epoch :  415 - cost:  0.33378062 - MSE:  0.01101367475820452 - train Accuracy:  0.9879888\n",
      "epoch :  416 - cost:  0.33375221 - MSE:  0.01101214470436197 - train Accuracy:  0.9879888\n",
      "epoch :  417 - cost:  0.33372375 - MSE:  0.011010268532530362 - train Accuracy:  0.9879888\n",
      "epoch :  418 - cost:  0.3336941 - MSE:  0.011007857803221558 - train Accuracy:  0.98798376\n",
      "epoch :  419 - cost:  0.3336607 - MSE:  0.011003806069876216 - train Accuracy:  0.9879914\n",
      "epoch :  420 - cost:  0.33362567 - MSE:  0.010997929535479107 - train Accuracy:  0.9879914\n",
      "epoch :  421 - cost:  0.33356684 - MSE:  0.010982638441203837 - train Accuracy:  0.9880015\n",
      "epoch :  422 - cost:  0.33347255 - MSE:  0.010941043643324948 - train Accuracy:  0.988004\n",
      "epoch :  423 - cost:  0.33340666 - MSE:  0.010866599292279042 - train Accuracy:  0.98794836\n",
      "epoch :  424 - cost:  0.33377898 - MSE:  0.010990695643933582 - train Accuracy:  0.9865972\n",
      "epoch :  425 - cost:  0.3335361 - MSE:  0.010929009893198421 - train Accuracy:  0.98726517\n",
      "epoch :  426 - cost:  0.3334909 - MSE:  0.010905976741769678 - train Accuracy:  0.98726773\n",
      "epoch :  427 - cost:  0.33325514 - MSE:  0.010777119634647798 - train Accuracy:  0.98794836\n",
      "epoch :  428 - cost:  0.33322293 - MSE:  0.010854136997358915 - train Accuracy:  0.98807234\n",
      "epoch :  429 - cost:  0.3330591 - MSE:  0.010637755685032228 - train Accuracy:  0.9882292\n",
      "epoch :  430 - cost:  0.33318245 - MSE:  0.010745409438003383 - train Accuracy:  0.988085\n",
      "epoch :  431 - cost:  0.33320463 - MSE:  0.010949527335865678 - train Accuracy:  0.98799896\n",
      "epoch :  432 - cost:  0.33316994 - MSE:  0.010937567537960899 - train Accuracy:  0.9880091\n",
      "epoch :  433 - cost:  0.33314186 - MSE:  0.010927611526350509 - train Accuracy:  0.9880091\n",
      "epoch :  434 - cost:  0.33311263 - MSE:  0.010920950281186871 - train Accuracy:  0.98801666\n",
      "epoch :  435 - cost:  0.33308622 - MSE:  0.010919007857469068 - train Accuracy:  0.98801416\n",
      "epoch :  436 - cost:  0.3330583 - MSE:  0.010919109919162992 - train Accuracy:  0.98801666\n",
      "epoch :  437 - cost:  0.3330321 - MSE:  0.010922836637024627 - train Accuracy:  0.9880293\n",
      "epoch :  438 - cost:  0.33300576 - MSE:  0.01092355171774991 - train Accuracy:  0.9880268\n",
      "epoch :  439 - cost:  0.33298036 - MSE:  0.010924265542585689 - train Accuracy:  0.9880268\n",
      "epoch :  440 - cost:  0.33295578 - MSE:  0.010922763030224084 - train Accuracy:  0.9880243\n",
      "epoch :  441 - cost:  0.33292946 - MSE:  0.010923461235294602 - train Accuracy:  0.9880293\n",
      "epoch :  442 - cost:  0.33290446 - MSE:  0.010926853778125783 - train Accuracy:  0.9880293\n",
      "epoch :  443 - cost:  0.33288056 - MSE:  0.01092466848380044 - train Accuracy:  0.98803186\n",
      "epoch :  444 - cost:  0.33285633 - MSE:  0.010925967026744492 - train Accuracy:  0.9880293\n",
      "epoch :  445 - cost:  0.33283266 - MSE:  0.010924500889175903 - train Accuracy:  0.98803437\n",
      "epoch :  446 - cost:  0.33280846 - MSE:  0.010925320682624518 - train Accuracy:  0.98803186\n",
      "epoch :  447 - cost:  0.33278507 - MSE:  0.010926752019203564 - train Accuracy:  0.98803186\n",
      "epoch :  448 - cost:  0.33276126 - MSE:  0.010927998792404558 - train Accuracy:  0.98803186\n",
      "epoch :  449 - cost:  0.33273837 - MSE:  0.0109289243710978 - train Accuracy:  0.98803186\n",
      "epoch :  450 - cost:  0.33271518 - MSE:  0.010929520262276808 - train Accuracy:  0.98803437\n",
      "epoch :  451 - cost:  0.3326925 - MSE:  0.010929992446758501 - train Accuracy:  0.98803437\n",
      "epoch :  452 - cost:  0.33267027 - MSE:  0.010930279628763166 - train Accuracy:  0.98803437\n",
      "epoch :  453 - cost:  0.3326462 - MSE:  0.010928041137068611 - train Accuracy:  0.98803437\n",
      "epoch :  454 - cost:  0.3326224 - MSE:  0.01092750193815293 - train Accuracy:  0.98803693\n",
      "epoch :  455 - cost:  0.33259824 - MSE:  0.010925890623071553 - train Accuracy:  0.9880445\n",
      "epoch :  456 - cost:  0.3325753 - MSE:  0.010924161953894927 - train Accuracy:  0.988042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  457 - cost:  0.3325536 - MSE:  0.010924250741756392 - train Accuracy:  0.988042\n",
      "epoch :  458 - cost:  0.33253184 - MSE:  0.010921617300843461 - train Accuracy:  0.9880445\n",
      "epoch :  459 - cost:  0.33250993 - MSE:  0.010923729531394557 - train Accuracy:  0.98803943\n",
      "epoch :  460 - cost:  0.33248705 - MSE:  0.010924364267803967 - train Accuracy:  0.98803943\n",
      "epoch :  461 - cost:  0.33246556 - MSE:  0.010923285955449263 - train Accuracy:  0.9880445\n",
      "epoch :  462 - cost:  0.33244342 - MSE:  0.010923259701451716 - train Accuracy:  0.988042\n",
      "epoch :  463 - cost:  0.33242202 - MSE:  0.01091827543906449 - train Accuracy:  0.988042\n",
      "epoch :  464 - cost:  0.33239973 - MSE:  0.01091955574222052 - train Accuracy:  0.98804706\n",
      "epoch :  465 - cost:  0.33237848 - MSE:  0.010922603862451039 - train Accuracy:  0.988042\n",
      "epoch :  466 - cost:  0.33235735 - MSE:  0.010919268504595956 - train Accuracy:  0.98804957\n",
      "epoch :  467 - cost:  0.3323361 - MSE:  0.010925125886962138 - train Accuracy:  0.988042\n",
      "epoch :  468 - cost:  0.3323156 - MSE:  0.010917835261682156 - train Accuracy:  0.9880521\n",
      "epoch :  469 - cost:  0.33229434 - MSE:  0.010926721747155053 - train Accuracy:  0.9880521\n",
      "epoch :  470 - cost:  0.3322738 - MSE:  0.010918445151197866 - train Accuracy:  0.98805714\n",
      "epoch :  471 - cost:  0.33225384 - MSE:  0.010928914544304748 - train Accuracy:  0.9880521\n",
      "epoch :  472 - cost:  0.332233 - MSE:  0.01091816107333665 - train Accuracy:  0.98805463\n",
      "epoch :  473 - cost:  0.3322119 - MSE:  0.010929777570113281 - train Accuracy:  0.98805463\n",
      "epoch :  474 - cost:  0.3321922 - MSE:  0.01091956134959859 - train Accuracy:  0.98805463\n",
      "epoch :  475 - cost:  0.33217263 - MSE:  0.010930994486065469 - train Accuracy:  0.98805463\n",
      "epoch :  476 - cost:  0.33215204 - MSE:  0.01092009655415261 - train Accuracy:  0.98805463\n",
      "epoch :  477 - cost:  0.33213207 - MSE:  0.010932092022993715 - train Accuracy:  0.98796606\n",
      "epoch :  478 - cost:  0.33211175 - MSE:  0.010921292665317169 - train Accuracy:  0.9879686\n",
      "epoch :  479 - cost:  0.33209214 - MSE:  0.010932833493504653 - train Accuracy:  0.98796606\n",
      "epoch :  480 - cost:  0.3320728 - MSE:  0.010922327256970945 - train Accuracy:  0.9879686\n",
      "epoch :  481 - cost:  0.33205268 - MSE:  0.010933560149398856 - train Accuracy:  0.98796606\n",
      "epoch :  482 - cost:  0.33203274 - MSE:  0.010923570197041899 - train Accuracy:  0.9879711\n",
      "epoch :  483 - cost:  0.33201334 - MSE:  0.010934502109418952 - train Accuracy:  0.98796606\n",
      "epoch :  484 - cost:  0.33199376 - MSE:  0.010925156391443185 - train Accuracy:  0.9879737\n",
      "epoch :  485 - cost:  0.33197424 - MSE:  0.010935733655058505 - train Accuracy:  0.98796606\n",
      "epoch :  486 - cost:  0.33195466 - MSE:  0.010926710859404701 - train Accuracy:  0.9879762\n",
      "epoch :  487 - cost:  0.33193597 - MSE:  0.010937189648342546 - train Accuracy:  0.9879686\n",
      "epoch :  488 - cost:  0.33191723 - MSE:  0.01092863500967797 - train Accuracy:  0.9879787\n",
      "epoch :  489 - cost:  0.3318981 - MSE:  0.010938733753657148 - train Accuracy:  0.9879686\n",
      "epoch :  490 - cost:  0.33187935 - MSE:  0.01093050132800104 - train Accuracy:  0.9879787\n",
      "epoch :  491 - cost:  0.33186126 - MSE:  0.010939799409142616 - train Accuracy:  0.9879711\n",
      "epoch :  492 - cost:  0.3318426 - MSE:  0.010932458030518698 - train Accuracy:  0.9879787\n",
      "epoch :  493 - cost:  0.33182392 - MSE:  0.010940848747815793 - train Accuracy:  0.9879762\n",
      "epoch :  494 - cost:  0.33180574 - MSE:  0.010934320689906504 - train Accuracy:  0.9879787\n",
      "epoch :  495 - cost:  0.33178747 - MSE:  0.010941814647482779 - train Accuracy:  0.9879787\n",
      "epoch :  496 - cost:  0.33176968 - MSE:  0.010935262750679721 - train Accuracy:  0.9879787\n",
      "epoch :  497 - cost:  0.331751 - MSE:  0.010941604090047451 - train Accuracy:  0.98798376\n",
      "epoch :  498 - cost:  0.33173335 - MSE:  0.010935421663322217 - train Accuracy:  0.9879863\n",
      "epoch :  499 - cost:  0.33171508 - MSE:  0.010942634642649518 - train Accuracy:  0.98798376\n",
      "epoch :  500 - cost:  0.33169752 - MSE:  0.010937670991984049 - train Accuracy:  0.9879863\n",
      "epoch :  501 - cost:  0.33167967 - MSE:  0.01094463328367896 - train Accuracy:  0.9879863\n",
      "epoch :  502 - cost:  0.33166218 - MSE:  0.010940219898117064 - train Accuracy:  0.9879888\n",
      "epoch :  503 - cost:  0.3316442 - MSE:  0.01094662411363028 - train Accuracy:  0.9879863\n",
      "epoch :  504 - cost:  0.331627 - MSE:  0.010942608259597598 - train Accuracy:  0.9879914\n",
      "epoch :  505 - cost:  0.3316092 - MSE:  0.010948308099195258 - train Accuracy:  0.98799646\n",
      "epoch :  506 - cost:  0.3315925 - MSE:  0.010944773486878617 - train Accuracy:  0.9879939\n",
      "epoch :  507 - cost:  0.33157492 - MSE:  0.010949801744131382 - train Accuracy:  0.98799646\n",
      "epoch :  508 - cost:  0.33155838 - MSE:  0.010947041969723542 - train Accuracy:  0.9879914\n",
      "epoch :  509 - cost:  0.33154106 - MSE:  0.010951201163667589 - train Accuracy:  0.98799646\n",
      "epoch :  510 - cost:  0.33152488 - MSE:  0.01094860163914663 - train Accuracy:  0.9879914\n",
      "epoch :  511 - cost:  0.33150718 - MSE:  0.010952324458528931 - train Accuracy:  0.988004\n",
      "epoch :  512 - cost:  0.33149046 - MSE:  0.01094957662885655 - train Accuracy:  0.98799896\n",
      "epoch :  513 - cost:  0.33147427 - MSE:  0.010953175578932633 - train Accuracy:  0.9880015\n",
      "epoch :  514 - cost:  0.33145738 - MSE:  0.010950507306119796 - train Accuracy:  0.9880015\n",
      "epoch :  515 - cost:  0.3314412 - MSE:  0.010954247331887653 - train Accuracy:  0.9880015\n",
      "epoch :  516 - cost:  0.33142528 - MSE:  0.010951932303071324 - train Accuracy:  0.9880015\n",
      "epoch :  517 - cost:  0.33140862 - MSE:  0.010955717509417212 - train Accuracy:  0.9880015\n",
      "epoch :  518 - cost:  0.33139288 - MSE:  0.010953742032418074 - train Accuracy:  0.9880015\n",
      "epoch :  519 - cost:  0.33137614 - MSE:  0.010957190862100029 - train Accuracy:  0.98799896\n",
      "epoch :  520 - cost:  0.33136 - MSE:  0.010955333777070033 - train Accuracy:  0.9880015\n",
      "epoch :  521 - cost:  0.3313438 - MSE:  0.01095849504683752 - train Accuracy:  0.98799896\n",
      "epoch :  522 - cost:  0.33132815 - MSE:  0.010956735656972867 - train Accuracy:  0.9880015\n",
      "epoch :  523 - cost:  0.3313124 - MSE:  0.010959580183925071 - train Accuracy:  0.98799896\n",
      "epoch :  524 - cost:  0.33129597 - MSE:  0.010958128661762897 - train Accuracy:  0.9880015\n",
      "epoch :  525 - cost:  0.3312805 - MSE:  0.010960565393977573 - train Accuracy:  0.98799896\n",
      "epoch :  526 - cost:  0.33126426 - MSE:  0.010959361783159868 - train Accuracy:  0.9880015\n",
      "epoch :  527 - cost:  0.33124843 - MSE:  0.010961331415358981 - train Accuracy:  0.98799896\n",
      "epoch :  528 - cost:  0.33123362 - MSE:  0.01096036691700091 - train Accuracy:  0.98799896\n",
      "epoch :  529 - cost:  0.33121789 - MSE:  0.010962061964261726 - train Accuracy:  0.988004\n",
      "epoch :  530 - cost:  0.3312026 - MSE:  0.010961523084001449 - train Accuracy:  0.988004\n",
      "epoch :  531 - cost:  0.33118775 - MSE:  0.010962809087151927 - train Accuracy:  0.988004\n",
      "epoch :  532 - cost:  0.33117288 - MSE:  0.010962545871099044 - train Accuracy:  0.988004\n",
      "epoch :  533 - cost:  0.3311575 - MSE:  0.010963406243474706 - train Accuracy:  0.988004\n",
      "epoch :  534 - cost:  0.33114314 - MSE:  0.010963312103544308 - train Accuracy:  0.988004\n",
      "epoch :  535 - cost:  0.3311284 - MSE:  0.010963735367356873 - train Accuracy:  0.988004\n",
      "epoch :  536 - cost:  0.33111337 - MSE:  0.010963674209180664 - train Accuracy:  0.988004\n",
      "epoch :  537 - cost:  0.33109868 - MSE:  0.01096383260009802 - train Accuracy:  0.988004\n",
      "epoch :  538 - cost:  0.33108386 - MSE:  0.010963810257002068 - train Accuracy:  0.988004\n",
      "epoch :  539 - cost:  0.3310692 - MSE:  0.010963817618161275 - train Accuracy:  0.988004\n",
      "epoch :  540 - cost:  0.3310547 - MSE:  0.01096383464684218 - train Accuracy:  0.988004\n",
      "epoch :  541 - cost:  0.33104008 - MSE:  0.010964083226134756 - train Accuracy:  0.98800653\n",
      "epoch :  542 - cost:  0.33102572 - MSE:  0.010964400476666322 - train Accuracy:  0.98800653\n",
      "epoch :  543 - cost:  0.3310115 - MSE:  0.010964718459329609 - train Accuracy:  0.98800653\n",
      "epoch :  544 - cost:  0.33099717 - MSE:  0.010965082285151561 - train Accuracy:  0.98800653\n",
      "epoch :  545 - cost:  0.33098313 - MSE:  0.010965577167755975 - train Accuracy:  0.98800653\n",
      "epoch :  546 - cost:  0.3309683 - MSE:  0.010966085353873754 - train Accuracy:  0.9880116\n",
      "epoch :  547 - cost:  0.33095407 - MSE:  0.010966606067853038 - train Accuracy:  0.9880091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  548 - cost:  0.33093905 - MSE:  0.010967251249078146 - train Accuracy:  0.9880116\n",
      "epoch :  549 - cost:  0.33092484 - MSE:  0.010968026067388476 - train Accuracy:  0.9880116\n",
      "epoch :  550 - cost:  0.33091024 - MSE:  0.010969043315262385 - train Accuracy:  0.98801416\n",
      "epoch :  551 - cost:  0.33089474 - MSE:  0.01097053515364783 - train Accuracy:  0.9880243\n",
      "epoch :  552 - cost:  0.33087978 - MSE:  0.010969132875889112 - train Accuracy:  0.9880243\n",
      "epoch :  553 - cost:  0.33086568 - MSE:  0.010970652022933961 - train Accuracy:  0.98802173\n",
      "epoch :  554 - cost:  0.3308514 - MSE:  0.010969915027593565 - train Accuracy:  0.9880268\n",
      "epoch :  555 - cost:  0.33083767 - MSE:  0.01097235949380029 - train Accuracy:  0.9880268\n",
      "epoch :  556 - cost:  0.33082482 - MSE:  0.010969755221313075 - train Accuracy:  0.98802173\n",
      "epoch :  557 - cost:  0.33081144 - MSE:  0.01097379721974463 - train Accuracy:  0.9880268\n",
      "epoch :  558 - cost:  0.33079848 - MSE:  0.010970180410809289 - train Accuracy:  0.98802173\n",
      "epoch :  559 - cost:  0.3307841 - MSE:  0.010974109319713016 - train Accuracy:  0.9880243\n",
      "epoch :  560 - cost:  0.33077115 - MSE:  0.01097204996559125 - train Accuracy:  0.98802173\n",
      "epoch :  561 - cost:  0.33075845 - MSE:  0.01097613823121585 - train Accuracy:  0.9880243\n",
      "epoch :  562 - cost:  0.33074576 - MSE:  0.010972400645494535 - train Accuracy:  0.98801416\n",
      "epoch :  563 - cost:  0.33073086 - MSE:  0.010976106939959266 - train Accuracy:  0.9880243\n",
      "epoch :  564 - cost:  0.3307179 - MSE:  0.010974544452669153 - train Accuracy:  0.98802173\n",
      "epoch :  565 - cost:  0.33070564 - MSE:  0.01097847014458034 - train Accuracy:  0.9880243\n",
      "epoch :  566 - cost:  0.3306937 - MSE:  0.010974783139114663 - train Accuracy:  0.9880192\n",
      "epoch :  567 - cost:  0.33067715 - MSE:  0.010978050839598796 - train Accuracy:  0.9880243\n",
      "epoch :  568 - cost:  0.33066517 - MSE:  0.01097705199472819 - train Accuracy:  0.9880243\n",
      "epoch :  569 - cost:  0.3306536 - MSE:  0.0109808873942827 - train Accuracy:  0.9880293\n",
      "epoch :  570 - cost:  0.33064306 - MSE:  0.010977387807477803 - train Accuracy:  0.9880192\n",
      "epoch :  571 - cost:  0.33062497 - MSE:  0.010979414444663207 - train Accuracy:  0.98803186\n",
      "epoch :  572 - cost:  0.3306132 - MSE:  0.010981581753649688 - train Accuracy:  0.9880268\n",
      "epoch :  573 - cost:  0.33060318 - MSE:  0.010979663865638105 - train Accuracy:  0.98802173\n",
      "epoch :  574 - cost:  0.33059055 - MSE:  0.01098383782484245 - train Accuracy:  0.98803186\n",
      "epoch :  575 - cost:  0.33058134 - MSE:  0.010980982877006103 - train Accuracy:  0.9880243\n",
      "epoch :  576 - cost:  0.3305637 - MSE:  0.010982036550102124 - train Accuracy:  0.9880293\n",
      "epoch :  577 - cost:  0.33055416 - MSE:  0.010985248087422475 - train Accuracy:  0.9880268\n",
      "epoch :  578 - cost:  0.33054566 - MSE:  0.010985051013654152 - train Accuracy:  0.9880243\n",
      "epoch :  579 - cost:  0.3305288 - MSE:  0.010983915979479567 - train Accuracy:  0.9880268\n",
      "epoch :  580 - cost:  0.3305182 - MSE:  0.010988416908643472 - train Accuracy:  0.98803186\n",
      "epoch :  581 - cost:  0.33051044 - MSE:  0.010993188757757164 - train Accuracy:  0.9880192\n",
      "epoch :  582 - cost:  0.33049694 - MSE:  0.01098574596114318 - train Accuracy:  0.9880243\n",
      "epoch :  583 - cost:  0.33048013 - MSE:  0.010984785481457517 - train Accuracy:  0.98803186\n",
      "epoch :  584 - cost:  0.3304693 - MSE:  0.010986678955883207 - train Accuracy:  0.9880293\n",
      "epoch :  585 - cost:  0.33045942 - MSE:  0.010987595350421231 - train Accuracy:  0.9880243\n",
      "epoch :  586 - cost:  0.330442 - MSE:  0.010987409647152809 - train Accuracy:  0.98803186\n",
      "epoch :  587 - cost:  0.33043548 - MSE:  0.010990590928242908 - train Accuracy:  0.98802173\n",
      "epoch :  588 - cost:  0.33042398 - MSE:  0.010990027000331122 - train Accuracy:  0.9880243\n",
      "epoch :  589 - cost:  0.33040917 - MSE:  0.01098980416044639 - train Accuracy:  0.9880268\n",
      "epoch :  590 - cost:  0.3303975 - MSE:  0.01099305124032083 - train Accuracy:  0.98803186\n",
      "epoch :  591 - cost:  0.33039105 - MSE:  0.010998115197774478 - train Accuracy:  0.98802173\n",
      "epoch :  592 - cost:  0.33037657 - MSE:  0.010991886446628537 - train Accuracy:  0.9880243\n",
      "epoch :  593 - cost:  0.33036113 - MSE:  0.010991861021085833 - train Accuracy:  0.98803186\n",
      "epoch :  594 - cost:  0.33035502 - MSE:  0.010994256036546655 - train Accuracy:  0.98802173\n",
      "epoch :  595 - cost:  0.33034194 - MSE:  0.010993067294983264 - train Accuracy:  0.9880243\n",
      "epoch :  596 - cost:  0.33032367 - MSE:  0.010994721709741319 - train Accuracy:  0.98803693\n",
      "epoch :  597 - cost:  0.33031377 - MSE:  0.010996513409740774 - train Accuracy:  0.98803693\n",
      "epoch :  598 - cost:  0.33030593 - MSE:  0.010995700355240216 - train Accuracy:  0.9880268\n",
      "epoch :  599 - cost:  0.33029404 - MSE:  0.010998657167033023 - train Accuracy:  0.98803186\n",
      "epoch :  600 - cost:  0.33028913 - MSE:  0.01100626877962464 - train Accuracy:  0.9880192\n",
      "epoch :  601 - cost:  0.33027598 - MSE:  0.010998532107662209 - train Accuracy:  0.9880243\n",
      "epoch :  602 - cost:  0.33025718 - MSE:  0.010998921562738078 - train Accuracy:  0.98803943\n",
      "epoch :  603 - cost:  0.33025005 - MSE:  0.01100133956254737 - train Accuracy:  0.9880293\n",
      "epoch :  604 - cost:  0.3302454 - MSE:  0.01100970960892169 - train Accuracy:  0.9880192\n",
      "epoch :  605 - cost:  0.33023113 - MSE:  0.011000309292689475 - train Accuracy:  0.9880243\n",
      "epoch :  606 - cost:  0.3302124 - MSE:  0.01100145245969152 - train Accuracy:  0.98803943\n",
      "epoch :  607 - cost:  0.33020252 - MSE:  0.01100340104249141 - train Accuracy:  0.98803693\n",
      "epoch :  608 - cost:  0.330195 - MSE:  0.011002736150871857 - train Accuracy:  0.98803186\n",
      "epoch :  609 - cost:  0.33018705 - MSE:  0.011005283204808744 - train Accuracy:  0.98802173\n",
      "epoch :  610 - cost:  0.33017927 - MSE:  0.011008818388467607 - train Accuracy:  0.98802173\n",
      "epoch :  611 - cost:  0.33016637 - MSE:  0.011005484092776057 - train Accuracy:  0.9880243\n",
      "epoch :  612 - cost:  0.33014748 - MSE:  0.011006238256681627 - train Accuracy:  0.98803943\n",
      "epoch :  613 - cost:  0.33013767 - MSE:  0.01100769083852842 - train Accuracy:  0.98803693\n",
      "epoch :  614 - cost:  0.3301298 - MSE:  0.01100753411175156 - train Accuracy:  0.98803186\n",
      "epoch :  615 - cost:  0.3301207 - MSE:  0.011009623165965285 - train Accuracy:  0.98802173\n",
      "epoch :  616 - cost:  0.33011496 - MSE:  0.01101734008246835 - train Accuracy:  0.98802173\n",
      "epoch :  617 - cost:  0.33010137 - MSE:  0.01101049713823196 - train Accuracy:  0.98802173\n",
      "epoch :  618 - cost:  0.33008474 - MSE:  0.011011144865847622 - train Accuracy:  0.98803943\n",
      "epoch :  619 - cost:  0.330081 - MSE:  0.011009891963699146 - train Accuracy:  0.9880243\n",
      "epoch :  620 - cost:  0.33006236 - MSE:  0.011009569839976242 - train Accuracy:  0.98803943\n",
      "epoch :  621 - cost:  0.33004993 - MSE:  0.011012083892321379 - train Accuracy:  0.98803693\n",
      "epoch :  622 - cost:  0.33003956 - MSE:  0.0110122116943852 - train Accuracy:  0.988042\n",
      "epoch :  623 - cost:  0.33003184 - MSE:  0.011013151059944501 - train Accuracy:  0.98803693\n",
      "epoch :  624 - cost:  0.33002737 - MSE:  0.01101549697115005 - train Accuracy:  0.98803437\n",
      "epoch :  625 - cost:  0.33001086 - MSE:  0.011014544698407316 - train Accuracy:  0.98803437\n",
      "epoch :  626 - cost:  0.33000532 - MSE:  0.011015255122276356 - train Accuracy:  0.98802173\n",
      "epoch :  627 - cost:  0.32999724 - MSE:  0.011015614790511611 - train Accuracy:  0.98803186\n",
      "epoch :  628 - cost:  0.3299819 - MSE:  0.011016099730111995 - train Accuracy:  0.98803693\n",
      "epoch :  629 - cost:  0.32997423 - MSE:  0.01101520214324913 - train Accuracy:  0.9880268\n",
      "epoch :  630 - cost:  0.32995886 - MSE:  0.011015959332336341 - train Accuracy:  0.9880445\n",
      "epoch :  631 - cost:  0.32995576 - MSE:  0.011015146839167845 - train Accuracy:  0.9880268\n",
      "epoch :  632 - cost:  0.32993975 - MSE:  0.011016708442429444 - train Accuracy:  0.9880445\n",
      "epoch :  633 - cost:  0.32993165 - MSE:  0.01101790886855378 - train Accuracy:  0.9880293\n",
      "epoch :  634 - cost:  0.329926 - MSE:  0.011019854855197738 - train Accuracy:  0.98803186\n",
      "epoch :  635 - cost:  0.3299088 - MSE:  0.011020442164199772 - train Accuracy:  0.9880445\n",
      "epoch :  636 - cost:  0.32990554 - MSE:  0.011019476965335262 - train Accuracy:  0.9880268\n",
      "epoch :  637 - cost:  0.3298933 - MSE:  0.011019462226783227 - train Accuracy:  0.98803693\n",
      "epoch :  638 - cost:  0.32988232 - MSE:  0.01102091413755866 - train Accuracy:  0.9880293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  639 - cost:  0.3298774 - MSE:  0.011022378042256939 - train Accuracy:  0.98803186\n",
      "epoch :  640 - cost:  0.32986096 - MSE:  0.01102282094314922 - train Accuracy:  0.9880445\n",
      "epoch :  641 - cost:  0.32985413 - MSE:  0.011022446338263232 - train Accuracy:  0.98803437\n",
      "epoch :  642 - cost:  0.32984686 - MSE:  0.011022953005816672 - train Accuracy:  0.98803437\n",
      "epoch :  643 - cost:  0.3298304 - MSE:  0.011024438632079258 - train Accuracy:  0.98804706\n",
      "epoch :  644 - cost:  0.32982388 - MSE:  0.011024815013400446 - train Accuracy:  0.98803943\n",
      "epoch :  645 - cost:  0.32981548 - MSE:  0.011025605876292194 - train Accuracy:  0.98803186\n",
      "epoch :  646 - cost:  0.32981363 - MSE:  0.01103268061836824 - train Accuracy:  0.98803437\n",
      "epoch :  647 - cost:  0.32980046 - MSE:  0.011028409856208985 - train Accuracy:  0.98803693\n",
      "epoch :  648 - cost:  0.32978362 - MSE:  0.011029299256984601 - train Accuracy:  0.988042\n",
      "epoch :  649 - cost:  0.329775 - MSE:  0.011029074925475073 - train Accuracy:  0.9880445\n",
      "epoch :  650 - cost:  0.3297685 - MSE:  0.011028864582564466 - train Accuracy:  0.98803943\n",
      "epoch :  651 - cost:  0.32976025 - MSE:  0.011028962172762303 - train Accuracy:  0.98803437\n",
      "epoch :  652 - cost:  0.32975766 - MSE:  0.011035473086349668 - train Accuracy:  0.98803437\n",
      "epoch :  653 - cost:  0.3297444 - MSE:  0.011032134116585927 - train Accuracy:  0.98803693\n",
      "epoch :  654 - cost:  0.32972804 - MSE:  0.011033055109214623 - train Accuracy:  0.9880521\n",
      "epoch :  655 - cost:  0.32971874 - MSE:  0.011033074477527346 - train Accuracy:  0.98804706\n",
      "epoch :  656 - cost:  0.32970968 - MSE:  0.01103361975935116 - train Accuracy:  0.9880521\n",
      "epoch :  657 - cost:  0.32970095 - MSE:  0.011034100684829701 - train Accuracy:  0.98804706\n",
      "epoch :  658 - cost:  0.32969204 - MSE:  0.01103479658821157 - train Accuracy:  0.98804957\n",
      "epoch :  659 - cost:  0.32968375 - MSE:  0.01103522244824257 - train Accuracy:  0.98804957\n",
      "epoch :  660 - cost:  0.32967404 - MSE:  0.011036087248411564 - train Accuracy:  0.98804957\n",
      "epoch :  661 - cost:  0.32966554 - MSE:  0.011036465859416878 - train Accuracy:  0.98805463\n",
      "epoch :  662 - cost:  0.32965568 - MSE:  0.011037394064463578 - train Accuracy:  0.98804957\n",
      "epoch :  663 - cost:  0.3296477 - MSE:  0.011037836391169769 - train Accuracy:  0.98805463\n",
      "epoch :  664 - cost:  0.3296386 - MSE:  0.01103879089296927 - train Accuracy:  0.98804957\n",
      "epoch :  665 - cost:  0.3296294 - MSE:  0.011039260298932815 - train Accuracy:  0.98805463\n",
      "epoch :  666 - cost:  0.32961982 - MSE:  0.011040179838226286 - train Accuracy:  0.98804957\n",
      "epoch :  667 - cost:  0.32961193 - MSE:  0.011040629635674922 - train Accuracy:  0.98805463\n",
      "epoch :  668 - cost:  0.32960224 - MSE:  0.011041504083313693 - train Accuracy:  0.9880521\n",
      "epoch :  669 - cost:  0.32959405 - MSE:  0.011041956413685767 - train Accuracy:  0.98805463\n",
      "epoch :  670 - cost:  0.3295853 - MSE:  0.011042810260208494 - train Accuracy:  0.9880521\n",
      "epoch :  671 - cost:  0.32957655 - MSE:  0.011043215107999056 - train Accuracy:  0.98805463\n",
      "epoch :  672 - cost:  0.32956773 - MSE:  0.011044038175355294 - train Accuracy:  0.98805714\n",
      "epoch :  673 - cost:  0.32955998 - MSE:  0.011044467814024543 - train Accuracy:  0.98805714\n",
      "epoch :  674 - cost:  0.32955036 - MSE:  0.011045248981086895 - train Accuracy:  0.9880597\n",
      "epoch :  675 - cost:  0.32954225 - MSE:  0.01104568362544275 - train Accuracy:  0.98805714\n",
      "epoch :  676 - cost:  0.3295336 - MSE:  0.011046417031510396 - train Accuracy:  0.9880597\n",
      "epoch :  677 - cost:  0.329525 - MSE:  0.01104687173189633 - train Accuracy:  0.98805714\n",
      "epoch :  678 - cost:  0.32951683 - MSE:  0.011047571661447798 - train Accuracy:  0.9880597\n",
      "epoch :  679 - cost:  0.32950887 - MSE:  0.011048046113248817 - train Accuracy:  0.98805714\n",
      "epoch :  680 - cost:  0.32950032 - MSE:  0.011048720854864894 - train Accuracy:  0.9880622\n",
      "epoch :  681 - cost:  0.329492 - MSE:  0.011049212129967881 - train Accuracy:  0.9880597\n",
      "epoch :  682 - cost:  0.32948372 - MSE:  0.011049810150726546 - train Accuracy:  0.9880622\n",
      "epoch :  683 - cost:  0.3294755 - MSE:  0.011050319814359772 - train Accuracy:  0.9880597\n",
      "epoch :  684 - cost:  0.32946688 - MSE:  0.01105086313598605 - train Accuracy:  0.9880622\n",
      "epoch :  685 - cost:  0.32945868 - MSE:  0.011051409397674128 - train Accuracy:  0.9880597\n",
      "epoch :  686 - cost:  0.32945052 - MSE:  0.01105186271961657 - train Accuracy:  0.9880622\n",
      "epoch :  687 - cost:  0.32944277 - MSE:  0.011052467688898213 - train Accuracy:  0.9880597\n",
      "epoch :  688 - cost:  0.32943386 - MSE:  0.011052908036989575 - train Accuracy:  0.9880622\n",
      "epoch :  689 - cost:  0.32942632 - MSE:  0.0110535418313748 - train Accuracy:  0.9880597\n",
      "epoch :  690 - cost:  0.32941815 - MSE:  0.011053880139875606 - train Accuracy:  0.9880622\n",
      "epoch :  691 - cost:  0.32941037 - MSE:  0.011054573061432989 - train Accuracy:  0.9880597\n",
      "epoch :  692 - cost:  0.32940176 - MSE:  0.011054905535244793 - train Accuracy:  0.9880622\n",
      "epoch :  693 - cost:  0.32939383 - MSE:  0.01105557174993128 - train Accuracy:  0.9880597\n",
      "epoch :  694 - cost:  0.3293855 - MSE:  0.01105571059252897 - train Accuracy:  0.9880622\n",
      "epoch :  695 - cost:  0.32937792 - MSE:  0.011056458755168285 - train Accuracy:  0.9880597\n",
      "epoch :  696 - cost:  0.32936877 - MSE:  0.011056626658561277 - train Accuracy:  0.9880622\n",
      "epoch :  697 - cost:  0.3293618 - MSE:  0.011057411141611304 - train Accuracy:  0.9880622\n",
      "epoch :  698 - cost:  0.32935333 - MSE:  0.01105740483642288 - train Accuracy:  0.9880622\n",
      "epoch :  699 - cost:  0.32934597 - MSE:  0.011058377492967137 - train Accuracy:  0.9880597\n",
      "epoch :  700 - cost:  0.32933825 - MSE:  0.011058482947644832 - train Accuracy:  0.9880622\n",
      "epoch :  701 - cost:  0.32932973 - MSE:  0.011059318930987974 - train Accuracy:  0.9880622\n",
      "epoch :  702 - cost:  0.32932228 - MSE:  0.011059128462578765 - train Accuracy:  0.9880622\n",
      "epoch :  703 - cost:  0.329315 - MSE:  0.011060281914791482 - train Accuracy:  0.9880597\n",
      "epoch :  704 - cost:  0.32930678 - MSE:  0.011060344107132884 - train Accuracy:  0.9880622\n",
      "epoch :  705 - cost:  0.3292992 - MSE:  0.011061113949581432 - train Accuracy:  0.9880622\n",
      "epoch :  706 - cost:  0.32929105 - MSE:  0.011060768545599073 - train Accuracy:  0.9880597\n",
      "epoch :  707 - cost:  0.32928437 - MSE:  0.011062089357197755 - train Accuracy:  0.9880622\n",
      "epoch :  708 - cost:  0.32927573 - MSE:  0.011061890707748424 - train Accuracy:  0.9880622\n",
      "epoch :  709 - cost:  0.32926825 - MSE:  0.011062833734408386 - train Accuracy:  0.9880622\n",
      "epoch :  710 - cost:  0.32926124 - MSE:  0.011062130914399048 - train Accuracy:  0.9880597\n",
      "epoch :  711 - cost:  0.32925388 - MSE:  0.011063845081630774 - train Accuracy:  0.9880622\n",
      "epoch :  712 - cost:  0.32924512 - MSE:  0.011063612734035532 - train Accuracy:  0.9880622\n",
      "epoch :  713 - cost:  0.32923737 - MSE:  0.01106410517359162 - train Accuracy:  0.9880622\n",
      "epoch :  714 - cost:  0.3292301 - MSE:  0.01106361624600475 - train Accuracy:  0.9880622\n",
      "epoch :  715 - cost:  0.329223 - MSE:  0.01106514217582196 - train Accuracy:  0.9880622\n",
      "epoch :  716 - cost:  0.32921535 - MSE:  0.011063587376255173 - train Accuracy:  0.9880622\n",
      "epoch :  717 - cost:  0.3292093 - MSE:  0.011066342384111803 - train Accuracy:  0.9880597\n",
      "epoch :  718 - cost:  0.3292004 - MSE:  0.011066668143197067 - train Accuracy:  0.9880622\n",
      "epoch :  719 - cost:  0.32919282 - MSE:  0.01106457639385513 - train Accuracy:  0.9880597\n",
      "epoch :  720 - cost:  0.32918683 - MSE:  0.01106784448887432 - train Accuracy:  0.9880622\n",
      "epoch :  721 - cost:  0.3291782 - MSE:  0.011068310428198731 - train Accuracy:  0.98806477\n",
      "epoch :  722 - cost:  0.32917076 - MSE:  0.011065935558831699 - train Accuracy:  0.98806477\n",
      "epoch :  723 - cost:  0.32916588 - MSE:  0.01106935726817193 - train Accuracy:  0.98806477\n",
      "epoch :  724 - cost:  0.3291562 - MSE:  0.011069577732869743 - train Accuracy:  0.98806727\n",
      "epoch :  725 - cost:  0.3291492 - MSE:  0.011066969178952423 - train Accuracy:  0.9880622\n",
      "epoch :  726 - cost:  0.3291455 - MSE:  0.011070690878592176 - train Accuracy:  0.98806477\n",
      "epoch :  727 - cost:  0.32913536 - MSE:  0.011071466489406163 - train Accuracy:  0.98806727\n",
      "epoch :  728 - cost:  0.32912868 - MSE:  0.011065872710437463 - train Accuracy:  0.98805463\n",
      "epoch :  729 - cost:  0.32912952 - MSE:  0.011075058628326378 - train Accuracy:  0.98804957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  730 - cost:  0.32911298 - MSE:  0.011070732718216375 - train Accuracy:  0.98806477\n",
      "epoch :  731 - cost:  0.32910618 - MSE:  0.011066285921856574 - train Accuracy:  0.98805463\n",
      "epoch :  732 - cost:  0.32910135 - MSE:  0.011072813214841866 - train Accuracy:  0.98806477\n",
      "epoch :  733 - cost:  0.32909223 - MSE:  0.011072783444567287 - train Accuracy:  0.98806727\n",
      "epoch :  734 - cost:  0.32908353 - MSE:  0.011067272260581558 - train Accuracy:  0.98806727\n",
      "epoch :  735 - cost:  0.32907945 - MSE:  0.01107366566198837 - train Accuracy:  0.98806727\n",
      "epoch :  736 - cost:  0.3290692 - MSE:  0.01107304470433136 - train Accuracy:  0.98806727\n",
      "epoch :  737 - cost:  0.32906154 - MSE:  0.011068904975331641 - train Accuracy:  0.98806983\n",
      "epoch :  738 - cost:  0.32905793 - MSE:  0.011074308071393167 - train Accuracy:  0.98806727\n",
      "epoch :  739 - cost:  0.32904926 - MSE:  0.01107490648091138 - train Accuracy:  0.98806983\n",
      "epoch :  740 - cost:  0.32904077 - MSE:  0.0110696086631882 - train Accuracy:  0.98807234\n",
      "epoch :  741 - cost:  0.32903796 - MSE:  0.011075087412850322 - train Accuracy:  0.98806983\n",
      "epoch :  742 - cost:  0.32902747 - MSE:  0.011074098088418848 - train Accuracy:  0.98807234\n",
      "epoch :  743 - cost:  0.32902125 - MSE:  0.01106831390104228 - train Accuracy:  0.9880622\n",
      "epoch :  744 - cost:  0.3290166 - MSE:  0.011075907298434736 - train Accuracy:  0.98806983\n",
      "epoch :  745 - cost:  0.32900694 - MSE:  0.011074867835288842 - train Accuracy:  0.98807234\n",
      "epoch :  746 - cost:  0.3290025 - MSE:  0.011068301086861843 - train Accuracy:  0.9880622\n",
      "epoch :  747 - cost:  0.32900167 - MSE:  0.011079421296237502 - train Accuracy:  0.9880597\n",
      "epoch :  748 - cost:  0.32898465 - MSE:  0.011071880323800513 - train Accuracy:  0.98806983\n",
      "epoch :  749 - cost:  0.32897782 - MSE:  0.011070166415830805 - train Accuracy:  0.9880749\n",
      "epoch :  750 - cost:  0.3289729 - MSE:  0.011075563890160445 - train Accuracy:  0.98807234\n",
      "epoch :  751 - cost:  0.32896727 - MSE:  0.01106876649419801 - train Accuracy:  0.9880622\n",
      "epoch :  752 - cost:  0.3289694 - MSE:  0.011081775336056879 - train Accuracy:  0.9880622\n",
      "epoch :  753 - cost:  0.32895195 - MSE:  0.011075247263791237 - train Accuracy:  0.9880774\n",
      "epoch :  754 - cost:  0.32894912 - MSE:  0.011070676638481585 - train Accuracy:  0.98807234\n",
      "epoch :  755 - cost:  0.32893935 - MSE:  0.011077001103392475 - train Accuracy:  0.9880774\n",
      "epoch :  756 - cost:  0.3289331 - MSE:  0.011071411329334447 - train Accuracy:  0.98806983\n",
      "epoch :  757 - cost:  0.3289291 - MSE:  0.011079398190950954 - train Accuracy:  0.9880774\n",
      "epoch :  758 - cost:  0.3289195 - MSE:  0.011078418901809868 - train Accuracy:  0.98808247\n",
      "epoch :  759 - cost:  0.32890984 - MSE:  0.01107290261918147 - train Accuracy:  0.988085\n",
      "epoch :  760 - cost:  0.3289049 - MSE:  0.011077255689945446 - train Accuracy:  0.988085\n",
      "epoch :  761 - cost:  0.32890537 - MSE:  0.011072148922252882 - train Accuracy:  0.98807234\n",
      "epoch :  762 - cost:  0.32888997 - MSE:  0.011073178056004813 - train Accuracy:  0.98808753\n",
      "epoch :  763 - cost:  0.32888782 - MSE:  0.011080554002150337 - train Accuracy:  0.98808247\n",
      "epoch :  764 - cost:  0.32887813 - MSE:  0.011078800738601024 - train Accuracy:  0.98808247\n",
      "epoch :  765 - cost:  0.32887542 - MSE:  0.011073768841524072 - train Accuracy:  0.9880749\n",
      "epoch :  766 - cost:  0.3288733 - MSE:  0.011084900800251209 - train Accuracy:  0.9880774\n",
      "epoch :  767 - cost:  0.328858 - MSE:  0.011076269286724554 - train Accuracy:  0.98808753\n",
      "epoch :  768 - cost:  0.32885113 - MSE:  0.011076990119166467 - train Accuracy:  0.98809004\n",
      "epoch :  769 - cost:  0.3288481 - MSE:  0.011075233644104353 - train Accuracy:  0.9880774\n",
      "epoch :  770 - cost:  0.32884276 - MSE:  0.011083192165696223 - train Accuracy:  0.988085\n",
      "epoch :  771 - cost:  0.32883453 - MSE:  0.011082519891080262 - train Accuracy:  0.98808247\n",
      "epoch :  772 - cost:  0.3288254 - MSE:  0.011078918326873924 - train Accuracy:  0.988085\n",
      "epoch :  773 - cost:  0.3288234 - MSE:  0.01107653383460251 - train Accuracy:  0.98807997\n",
      "epoch :  774 - cost:  0.3288153 - MSE:  0.01108320789090154 - train Accuracy:  0.988085\n",
      "epoch :  775 - cost:  0.32880732 - MSE:  0.011079661468076154 - train Accuracy:  0.988085\n",
      "epoch :  776 - cost:  0.32880473 - MSE:  0.011077387642486336 - train Accuracy:  0.98807997\n",
      "epoch :  777 - cost:  0.32879725 - MSE:  0.011084279878087454 - train Accuracy:  0.98808247\n",
      "epoch :  778 - cost:  0.3287892 - MSE:  0.011082431367000566 - train Accuracy:  0.98808753\n",
      "epoch :  779 - cost:  0.32878545 - MSE:  0.011078380332709196 - train Accuracy:  0.98808247\n",
      "epoch :  780 - cost:  0.3287784 - MSE:  0.011085502338327934 - train Accuracy:  0.98808753\n",
      "epoch :  781 - cost:  0.3287713 - MSE:  0.011084341847981752 - train Accuracy:  0.98808247\n",
      "epoch :  782 - cost:  0.32876408 - MSE:  0.011079300507868421 - train Accuracy:  0.988085\n",
      "epoch :  783 - cost:  0.3287604 - MSE:  0.011086355048873214 - train Accuracy:  0.98809004\n",
      "epoch :  784 - cost:  0.32875305 - MSE:  0.011084875968258233 - train Accuracy:  0.98808753\n",
      "epoch :  785 - cost:  0.32874578 - MSE:  0.011079878969574165 - train Accuracy:  0.988085\n",
      "epoch :  786 - cost:  0.32874224 - MSE:  0.01108700887821381 - train Accuracy:  0.98809004\n",
      "epoch :  787 - cost:  0.32873443 - MSE:  0.01108521659787722 - train Accuracy:  0.98809004\n",
      "epoch :  788 - cost:  0.328728 - MSE:  0.011080404874612176 - train Accuracy:  0.98807997\n",
      "epoch :  789 - cost:  0.3287248 - MSE:  0.011087996386027974 - train Accuracy:  0.9880926\n",
      "epoch :  790 - cost:  0.32871675 - MSE:  0.01108603552172257 - train Accuracy:  0.98809004\n",
      "epoch :  791 - cost:  0.32871005 - MSE:  0.011081099045179156 - train Accuracy:  0.988085\n",
      "epoch :  792 - cost:  0.32870623 - MSE:  0.011088141700183527 - train Accuracy:  0.9880951\n",
      "epoch :  793 - cost:  0.32869837 - MSE:  0.01108592364854925 - train Accuracy:  0.98809767\n",
      "epoch :  794 - cost:  0.3286932 - MSE:  0.01108143925152349 - train Accuracy:  0.98808753\n",
      "epoch :  795 - cost:  0.32868952 - MSE:  0.011089435361041502 - train Accuracy:  0.9880926\n",
      "epoch :  796 - cost:  0.3286807 - MSE:  0.011087399049729085 - train Accuracy:  0.9880951\n",
      "epoch :  797 - cost:  0.32867366 - MSE:  0.01108235762232709 - train Accuracy:  0.98809767\n",
      "epoch :  798 - cost:  0.3286696 - MSE:  0.011088543255379791 - train Accuracy:  0.9881002\n",
      "epoch :  799 - cost:  0.32866156 - MSE:  0.011083587792416619 - train Accuracy:  0.9881002\n",
      "epoch :  800 - cost:  0.32865527 - MSE:  0.011083591401872109 - train Accuracy:  0.98810524\n",
      "epoch :  801 - cost:  0.3286503 - MSE:  0.011082650158720087 - train Accuracy:  0.9881002\n",
      "epoch :  802 - cost:  0.32864842 - MSE:  0.011090445130006907 - train Accuracy:  0.98809767\n",
      "epoch :  803 - cost:  0.32863954 - MSE:  0.011087873602271899 - train Accuracy:  0.98810273\n",
      "epoch :  804 - cost:  0.3286339 - MSE:  0.011083190981262196 - train Accuracy:  0.9880951\n",
      "epoch :  805 - cost:  0.32863104 - MSE:  0.011091209773566937 - train Accuracy:  0.98809767\n",
      "epoch :  806 - cost:  0.32862252 - MSE:  0.011088577553700754 - train Accuracy:  0.98810273\n",
      "epoch :  807 - cost:  0.32861668 - MSE:  0.011083731383360372 - train Accuracy:  0.9880951\n",
      "epoch :  808 - cost:  0.32861513 - MSE:  0.011092179734731544 - train Accuracy:  0.98809767\n",
      "epoch :  809 - cost:  0.3286052 - MSE:  0.011089499819930775 - train Accuracy:  0.98810273\n",
      "epoch :  810 - cost:  0.32859877 - MSE:  0.0110843039001433 - train Accuracy:  0.9881002\n",
      "epoch :  811 - cost:  0.32859576 - MSE:  0.011091794039834048 - train Accuracy:  0.98810273\n",
      "epoch :  812 - cost:  0.32858682 - MSE:  0.011088310958796045 - train Accuracy:  0.98810273\n",
      "epoch :  813 - cost:  0.32858813 - MSE:  0.011084618336471015 - train Accuracy:  0.98809004\n",
      "epoch :  814 - cost:  0.32857525 - MSE:  0.011086543880661708 - train Accuracy:  0.98810774\n",
      "epoch :  815 - cost:  0.32856965 - MSE:  0.011085659624918847 - train Accuracy:  0.98810774\n",
      "epoch :  816 - cost:  0.32856423 - MSE:  0.011086715928965605 - train Accuracy:  0.98810774\n",
      "epoch :  817 - cost:  0.3285581 - MSE:  0.011086273930643284 - train Accuracy:  0.98810774\n",
      "epoch :  818 - cost:  0.3285546 - MSE:  0.011085569020228817 - train Accuracy:  0.9881002\n",
      "epoch :  819 - cost:  0.32855543 - MSE:  0.011095638014867695 - train Accuracy:  0.9881002\n",
      "epoch :  820 - cost:  0.32854393 - MSE:  0.011088511401664076 - train Accuracy:  0.98810273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  821 - cost:  0.3285395 - MSE:  0.011084536615648422 - train Accuracy:  0.9881002\n",
      "epoch :  822 - cost:  0.328535 - MSE:  0.011092724008441503 - train Accuracy:  0.98810273\n",
      "epoch :  823 - cost:  0.32852602 - MSE:  0.011088470629011637 - train Accuracy:  0.98810524\n",
      "epoch :  824 - cost:  0.32852507 - MSE:  0.01108549807772946 - train Accuracy:  0.9880926\n",
      "epoch :  825 - cost:  0.3285212 - MSE:  0.011094631311143872 - train Accuracy:  0.9881002\n",
      "epoch :  826 - cost:  0.32851106 - MSE:  0.011090593924951597 - train Accuracy:  0.98810273\n",
      "epoch :  827 - cost:  0.32850745 - MSE:  0.011086380772413909 - train Accuracy:  0.9881002\n",
      "epoch :  828 - cost:  0.328503 - MSE:  0.011094512234783869 - train Accuracy:  0.98810273\n",
      "epoch :  829 - cost:  0.32849362 - MSE:  0.01109009860841231 - train Accuracy:  0.98810524\n",
      "epoch :  830 - cost:  0.3284901 - MSE:  0.011087400411854778 - train Accuracy:  0.98809767\n",
      "epoch :  831 - cost:  0.32848617 - MSE:  0.011095189773990852 - train Accuracy:  0.98810524\n",
      "epoch :  832 - cost:  0.32847682 - MSE:  0.011090300121586254 - train Accuracy:  0.98810774\n",
      "epoch :  833 - cost:  0.32847637 - MSE:  0.011087961750567523 - train Accuracy:  0.9880926\n",
      "epoch :  834 - cost:  0.32847375 - MSE:  0.01110008365097626 - train Accuracy:  0.9881002\n",
      "epoch :  835 - cost:  0.32846212 - MSE:  0.011092997694100066 - train Accuracy:  0.98810774\n",
      "epoch :  836 - cost:  0.32846102 - MSE:  0.01108870750177272 - train Accuracy:  0.9880951\n",
      "epoch :  837 - cost:  0.3284567 - MSE:  0.011097220663642438 - train Accuracy:  0.98810273\n",
      "epoch :  838 - cost:  0.32844606 - MSE:  0.011088465895971079 - train Accuracy:  0.9881103\n",
      "epoch :  839 - cost:  0.3284406 - MSE:  0.011091160779671032 - train Accuracy:  0.98810273\n",
      "epoch :  840 - cost:  0.32843837 - MSE:  0.011088839760533131 - train Accuracy:  0.98809767\n",
      "epoch :  841 - cost:  0.3284346 - MSE:  0.011097544242544896 - train Accuracy:  0.98810273\n",
      "epoch :  842 - cost:  0.3284248 - MSE:  0.011092628413177692 - train Accuracy:  0.98810774\n",
      "epoch :  843 - cost:  0.32842603 - MSE:  0.011089822390270487 - train Accuracy:  0.9880951\n",
      "epoch :  844 - cost:  0.3284146 - MSE:  0.01109350870139278 - train Accuracy:  0.98810774\n",
      "epoch :  845 - cost:  0.32841566 - MSE:  0.011090418183810121 - train Accuracy:  0.98809767\n",
      "epoch :  846 - cost:  0.32840636 - MSE:  0.011096330734761673 - train Accuracy:  0.98810524\n",
      "epoch :  847 - cost:  0.32840225 - MSE:  0.011090405443015566 - train Accuracy:  0.98810273\n",
      "epoch :  848 - cost:  0.32839748 - MSE:  0.011098279508436787 - train Accuracy:  0.9881103\n",
      "epoch :  849 - cost:  0.32838836 - MSE:  0.011092422021431233 - train Accuracy:  0.9881154\n",
      "epoch :  850 - cost:  0.32838383 - MSE:  0.011091116680337769 - train Accuracy:  0.9881128\n",
      "epoch :  851 - cost:  0.32838216 - MSE:  0.011098761510242538 - train Accuracy:  0.9881154\n",
      "epoch :  852 - cost:  0.32837203 - MSE:  0.011092794134111461 - train Accuracy:  0.9881179\n",
      "epoch :  853 - cost:  0.32837236 - MSE:  0.01109123656390335 - train Accuracy:  0.9880926\n",
      "epoch :  854 - cost:  0.32837307 - MSE:  0.011105648391962444 - train Accuracy:  0.98810774\n",
      "epoch :  855 - cost:  0.32835743 - MSE:  0.011091885950506822 - train Accuracy:  0.9881128\n",
      "epoch :  856 - cost:  0.32835636 - MSE:  0.011098667599551717 - train Accuracy:  0.9881154\n",
      "epoch :  857 - cost:  0.32834774 - MSE:  0.011092027765381297 - train Accuracy:  0.9881103\n",
      "epoch :  858 - cost:  0.32834917 - MSE:  0.011101905992439667 - train Accuracy:  0.9881154\n",
      "epoch :  859 - cost:  0.32833818 - MSE:  0.011095709103357694 - train Accuracy:  0.98812044\n",
      "epoch :  860 - cost:  0.32834068 - MSE:  0.011092595485765541 - train Accuracy:  0.9881002\n",
      "epoch :  861 - cost:  0.32833418 - MSE:  0.011092863046018593 - train Accuracy:  0.98810273\n",
      "epoch :  862 - cost:  0.32832927 - MSE:  0.01108874367668675 - train Accuracy:  0.9881103\n",
      "epoch :  863 - cost:  0.3283242 - MSE:  0.011093134859106195 - train Accuracy:  0.98810273\n",
      "epoch :  864 - cost:  0.32831624 - MSE:  0.011092044417748715 - train Accuracy:  0.9881128\n",
      "epoch :  865 - cost:  0.32831085 - MSE:  0.011091951405650804 - train Accuracy:  0.9881154\n",
      "epoch :  866 - cost:  0.32830644 - MSE:  0.011093676093729847 - train Accuracy:  0.9881963\n",
      "epoch :  867 - cost:  0.32830596 - MSE:  0.011087554630085858 - train Accuracy:  0.9882014\n",
      "epoch :  868 - cost:  0.32829887 - MSE:  0.011094018052182535 - train Accuracy:  0.9881938\n",
      "epoch :  869 - cost:  0.32829118 - MSE:  0.011090360739736406 - train Accuracy:  0.988209\n",
      "epoch :  870 - cost:  0.32828954 - MSE:  0.011094256356429954 - train Accuracy:  0.9881963\n",
      "epoch :  871 - cost:  0.32828018 - MSE:  0.011092498658542484 - train Accuracy:  0.98820645\n",
      "epoch :  872 - cost:  0.32827604 - MSE:  0.011092825708322925 - train Accuracy:  0.988209\n",
      "epoch :  873 - cost:  0.32827094 - MSE:  0.011092137224241268 - train Accuracy:  0.98820645\n",
      "epoch :  874 - cost:  0.32826772 - MSE:  0.011094725481567733 - train Accuracy:  0.9881989\n",
      "epoch :  875 - cost:  0.32826874 - MSE:  0.011087879672429628 - train Accuracy:  0.9881989\n",
      "epoch :  876 - cost:  0.32826075 - MSE:  0.011095349174504736 - train Accuracy:  0.9881963\n",
      "epoch :  877 - cost:  0.32825404 - MSE:  0.01109067124072553 - train Accuracy:  0.98820394\n",
      "epoch :  878 - cost:  0.32825083 - MSE:  0.011095422267204242 - train Accuracy:  0.98820394\n",
      "epoch :  879 - cost:  0.32825124 - MSE:  0.011104672719861253 - train Accuracy:  0.98820645\n",
      "epoch :  880 - cost:  0.32823798 - MSE:  0.011097490093846087 - train Accuracy:  0.9882191\n",
      "epoch :  881 - cost:  0.3282381 - MSE:  0.011095967528743624 - train Accuracy:  0.9881938\n",
      "epoch :  882 - cost:  0.32823244 - MSE:  0.01109611361346134 - train Accuracy:  0.9882014\n",
      "epoch :  883 - cost:  0.32822594 - MSE:  0.011101215767410305 - train Accuracy:  0.9882115\n",
      "epoch :  884 - cost:  0.3282243 - MSE:  0.01109664823389438 - train Accuracy:  0.9881938\n",
      "epoch :  885 - cost:  0.32821822 - MSE:  0.01109681884384642 - train Accuracy:  0.9881938\n",
      "epoch :  886 - cost:  0.32821015 - MSE:  0.01109560412416003 - train Accuracy:  0.9882115\n",
      "epoch :  887 - cost:  0.32820702 - MSE:  0.011092864342619657 - train Accuracy:  0.988209\n",
      "epoch :  888 - cost:  0.3282048 - MSE:  0.011097156172748325 - train Accuracy:  0.98820394\n",
      "epoch :  889 - cost:  0.32820415 - MSE:  0.011104781649469774 - train Accuracy:  0.9882115\n",
      "epoch :  890 - cost:  0.32819137 - MSE:  0.011098454517301532 - train Accuracy:  0.98822165\n",
      "epoch :  891 - cost:  0.32819113 - MSE:  0.01109750426917049 - train Accuracy:  0.98820645\n",
      "epoch :  892 - cost:  0.32818714 - MSE:  0.011104564784403066 - train Accuracy:  0.9882115\n",
      "epoch :  893 - cost:  0.32817832 - MSE:  0.011097688777215276 - train Accuracy:  0.988209\n",
      "epoch :  894 - cost:  0.3281805 - MSE:  0.011109767598443012 - train Accuracy:  0.98820394\n",
      "epoch :  895 - cost:  0.32816952 - MSE:  0.011101531966086034 - train Accuracy:  0.988209\n",
      "epoch :  896 - cost:  0.32816917 - MSE:  0.011098555359675575 - train Accuracy:  0.9881989\n",
      "epoch :  897 - cost:  0.328163 - MSE:  0.011099004133570631 - train Accuracy:  0.98820394\n",
      "epoch :  898 - cost:  0.3281611 - MSE:  0.011092293748820505 - train Accuracy:  0.9881963\n",
      "epoch :  899 - cost:  0.32815614 - MSE:  0.011098845317004391 - train Accuracy:  0.9882014\n",
      "epoch :  900 - cost:  0.32814932 - MSE:  0.01109870857462912 - train Accuracy:  0.9882014\n",
      "epoch :  901 - cost:  0.32815126 - MSE:  0.011110892323349516 - train Accuracy:  0.98820645\n",
      "epoch :  902 - cost:  0.32813728 - MSE:  0.01110015907652539 - train Accuracy:  0.988214\n",
      "epoch :  903 - cost:  0.32813725 - MSE:  0.011099137525466492 - train Accuracy:  0.9881989\n",
      "epoch :  904 - cost:  0.32812825 - MSE:  0.01109902084457832 - train Accuracy:  0.9882115\n",
      "epoch :  905 - cost:  0.32812968 - MSE:  0.01110776939347314 - train Accuracy:  0.988209\n",
      "epoch :  906 - cost:  0.3281195 - MSE:  0.011101160322209083 - train Accuracy:  0.9882166\n",
      "epoch :  907 - cost:  0.3281211 - MSE:  0.011099804165695865 - train Accuracy:  0.9881989\n",
      "epoch :  908 - cost:  0.3281158 - MSE:  0.011100049618108697 - train Accuracy:  0.9882014\n",
      "epoch :  909 - cost:  0.3281095 - MSE:  0.011099947974018462 - train Accuracy:  0.9882014\n",
      "epoch :  910 - cost:  0.32810313 - MSE:  0.011096521450315292 - train Accuracy:  0.98820645\n",
      "epoch :  911 - cost:  0.3281026 - MSE:  0.011100617877146873 - train Accuracy:  0.9882014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  912 - cost:  0.32809338 - MSE:  0.011096777127423692 - train Accuracy:  0.9882166\n",
      "epoch :  913 - cost:  0.3280934 - MSE:  0.011100662401942846 - train Accuracy:  0.9882014\n",
      "epoch :  914 - cost:  0.32808754 - MSE:  0.011094823495580301 - train Accuracy:  0.98820394\n",
      "epoch :  915 - cost:  0.32808512 - MSE:  0.011100200920798399 - train Accuracy:  0.9881989\n",
      "epoch :  916 - cost:  0.32808435 - MSE:  0.011107850876064225 - train Accuracy:  0.9882115\n",
      "epoch :  917 - cost:  0.32807103 - MSE:  0.011098415300282306 - train Accuracy:  0.9882166\n",
      "epoch :  918 - cost:  0.32806885 - MSE:  0.011103668223072623 - train Accuracy:  0.988214\n",
      "epoch :  919 - cost:  0.32806846 - MSE:  0.011100399602856284 - train Accuracy:  0.9881989\n",
      "epoch :  920 - cost:  0.32806325 - MSE:  0.011101238695235265 - train Accuracy:  0.9882014\n",
      "epoch :  921 - cost:  0.32805556 - MSE:  0.011096682637562541 - train Accuracy:  0.9882115\n",
      "epoch :  922 - cost:  0.3280561 - MSE:  0.011101071680126598 - train Accuracy:  0.9882014\n",
      "epoch :  923 - cost:  0.32804632 - MSE:  0.011100208891436834 - train Accuracy:  0.9882191\n",
      "epoch :  924 - cost:  0.32804567 - MSE:  0.01110557137169623 - train Accuracy:  0.988214\n",
      "epoch :  925 - cost:  0.328041 - MSE:  0.011101207427046313 - train Accuracy:  0.98820394\n",
      "epoch :  926 - cost:  0.32803664 - MSE:  0.011095910980002168 - train Accuracy:  0.988214\n",
      "epoch :  927 - cost:  0.32803333 - MSE:  0.011101702836274855 - train Accuracy:  0.9882014\n",
      "epoch :  928 - cost:  0.32802624 - MSE:  0.011097453807778856 - train Accuracy:  0.9882166\n",
      "epoch :  929 - cost:  0.32802436 - MSE:  0.011101982415741816 - train Accuracy:  0.9882014\n",
      "epoch :  930 - cost:  0.32801878 - MSE:  0.011096530524529405 - train Accuracy:  0.988214\n",
      "epoch :  931 - cost:  0.32801747 - MSE:  0.011102045152175936 - train Accuracy:  0.9882014\n",
      "epoch :  932 - cost:  0.32801348 - MSE:  0.011102138221868724 - train Accuracy:  0.98820394\n",
      "epoch :  933 - cost:  0.3280059 - MSE:  0.011102141675024687 - train Accuracy:  0.98820394\n",
      "epoch :  934 - cost:  0.32800692 - MSE:  0.01109285070557712 - train Accuracy:  0.9881989\n",
      "epoch :  935 - cost:  0.32800063 - MSE:  0.01110227982840397 - train Accuracy:  0.98820394\n",
      "epoch :  936 - cost:  0.327992 - MSE:  0.011101941804271648 - train Accuracy:  0.988214\n",
      "epoch :  937 - cost:  0.3279937 - MSE:  0.011109385161776576 - train Accuracy:  0.988209\n",
      "epoch :  938 - cost:  0.3279853 - MSE:  0.011102108357076923 - train Accuracy:  0.988214\n",
      "epoch :  939 - cost:  0.32798606 - MSE:  0.01111352440100559 - train Accuracy:  0.988209\n",
      "epoch :  940 - cost:  0.32797667 - MSE:  0.0111058148663015 - train Accuracy:  0.988214\n",
      "epoch :  941 - cost:  0.3279762 - MSE:  0.011102932250453074 - train Accuracy:  0.98820645\n",
      "epoch :  942 - cost:  0.32796797 - MSE:  0.01110047591456681 - train Accuracy:  0.988214\n",
      "epoch :  943 - cost:  0.3279641 - MSE:  0.011098735440961092 - train Accuracy:  0.9882191\n",
      "epoch :  944 - cost:  0.3279596 - MSE:  0.011102327938465238 - train Accuracy:  0.9882115\n",
      "epoch :  945 - cost:  0.3279604 - MSE:  0.011095622693412662 - train Accuracy:  0.988214\n",
      "epoch :  946 - cost:  0.32795537 - MSE:  0.011103589576042173 - train Accuracy:  0.9882115\n",
      "epoch :  947 - cost:  0.32795125 - MSE:  0.011103749875356624 - train Accuracy:  0.988214\n",
      "epoch :  948 - cost:  0.32794636 - MSE:  0.011103767000712672 - train Accuracy:  0.9882115\n",
      "epoch :  949 - cost:  0.32793954 - MSE:  0.011105174352597821 - train Accuracy:  0.98822415\n",
      "epoch :  950 - cost:  0.32793835 - MSE:  0.011103865786711081 - train Accuracy:  0.9882115\n",
      "epoch :  951 - cost:  0.32793108 - MSE:  0.01110238535572719 - train Accuracy:  0.98822415\n",
      "epoch :  952 - cost:  0.32793105 - MSE:  0.011097639008842239 - train Accuracy:  0.9882166\n",
      "epoch :  953 - cost:  0.32792488 - MSE:  0.011103434414921719 - train Accuracy:  0.9882166\n",
      "epoch :  954 - cost:  0.32792154 - MSE:  0.011098323675610972 - train Accuracy:  0.9882166\n",
      "epoch :  955 - cost:  0.32791653 - MSE:  0.011102852465423595 - train Accuracy:  0.9882166\n",
      "epoch :  956 - cost:  0.32791507 - MSE:  0.01109764582782005 - train Accuracy:  0.98822165\n",
      "epoch :  957 - cost:  0.32790995 - MSE:  0.011103740849774536 - train Accuracy:  0.988214\n",
      "epoch :  958 - cost:  0.32790455 - MSE:  0.011099749854820913 - train Accuracy:  0.98822165\n",
      "epoch :  959 - cost:  0.32789975 - MSE:  0.011100730099298229 - train Accuracy:  0.9882191\n",
      "epoch :  960 - cost:  0.32789466 - MSE:  0.01110137734190293 - train Accuracy:  0.9882267\n",
      "epoch :  961 - cost:  0.3278908 - MSE:  0.0111004764821597 - train Accuracy:  0.9882267\n",
      "epoch :  962 - cost:  0.32788983 - MSE:  0.011103917485083815 - train Accuracy:  0.9882166\n",
      "epoch :  963 - cost:  0.32788995 - MSE:  0.011095871723189503 - train Accuracy:  0.9882166\n",
      "epoch :  964 - cost:  0.32788473 - MSE:  0.011105449794670425 - train Accuracy:  0.9882115\n",
      "epoch :  965 - cost:  0.32788727 - MSE:  0.01111427141203668 - train Accuracy:  0.98822165\n",
      "epoch :  966 - cost:  0.3278756 - MSE:  0.01110699719949457 - train Accuracy:  0.9882343\n",
      "epoch :  967 - cost:  0.32787207 - MSE:  0.011105967820830835 - train Accuracy:  0.988214\n",
      "epoch :  968 - cost:  0.3278633 - MSE:  0.011101720643996936 - train Accuracy:  0.9882292\n",
      "epoch :  969 - cost:  0.32786041 - MSE:  0.011102348200374377 - train Accuracy:  0.9882292\n",
      "epoch :  970 - cost:  0.3278566 - MSE:  0.011101256005892757 - train Accuracy:  0.9882318\n",
      "epoch :  971 - cost:  0.32785308 - MSE:  0.011103357135820011 - train Accuracy:  0.9882292\n",
      "epoch :  972 - cost:  0.32785252 - MSE:  0.011099406748543175 - train Accuracy:  0.98822415\n",
      "epoch :  973 - cost:  0.32785285 - MSE:  0.011106729137518324 - train Accuracy:  0.98822165\n",
      "epoch :  974 - cost:  0.3278494 - MSE:  0.011109630891948162 - train Accuracy:  0.9882292\n",
      "epoch :  975 - cost:  0.32784086 - MSE:  0.01110445978090275 - train Accuracy:  0.98822165\n",
      "epoch :  976 - cost:  0.32783544 - MSE:  0.011100433646446434 - train Accuracy:  0.9882292\n",
      "epoch :  977 - cost:  0.32783106 - MSE:  0.011104276692861854 - train Accuracy:  0.9882267\n",
      "epoch :  978 - cost:  0.32783026 - MSE:  0.011098713419841854 - train Accuracy:  0.98822165\n",
      "epoch :  979 - cost:  0.32782975 - MSE:  0.011107346756977998 - train Accuracy:  0.9882191\n",
      "epoch :  980 - cost:  0.32782552 - MSE:  0.011106862317769629 - train Accuracy:  0.98822165\n",
      "epoch :  981 - cost:  0.32781976 - MSE:  0.011106366102875843 - train Accuracy:  0.98822415\n",
      "epoch :  982 - cost:  0.32781377 - MSE:  0.011104750529175204 - train Accuracy:  0.9882267\n",
      "epoch :  983 - cost:  0.32781038 - MSE:  0.01110207165825574 - train Accuracy:  0.9882292\n",
      "epoch :  984 - cost:  0.32780597 - MSE:  0.011102875894052655 - train Accuracy:  0.9882318\n",
      "epoch :  985 - cost:  0.32780197 - MSE:  0.011103303288809811 - train Accuracy:  0.9882318\n",
      "epoch :  986 - cost:  0.3277978 - MSE:  0.01110351010512758 - train Accuracy:  0.9882292\n",
      "epoch :  987 - cost:  0.32779497 - MSE:  0.011103583494324951 - train Accuracy:  0.9882318\n",
      "epoch :  988 - cost:  0.32779127 - MSE:  0.011103993307402398 - train Accuracy:  0.9882368\n",
      "epoch :  989 - cost:  0.32778808 - MSE:  0.011103683251539048 - train Accuracy:  0.9882318\n",
      "epoch :  990 - cost:  0.32778352 - MSE:  0.01110418726929853 - train Accuracy:  0.98823935\n",
      "epoch :  991 - cost:  0.3277802 - MSE:  0.011104497257983863 - train Accuracy:  0.9882368\n",
      "epoch :  992 - cost:  0.3277757 - MSE:  0.011104982877298603 - train Accuracy:  0.9882343\n",
      "epoch :  993 - cost:  0.3277751 - MSE:  0.011102293946711738 - train Accuracy:  0.9882318\n",
      "epoch :  994 - cost:  0.3277677 - MSE:  0.011104790481166235 - train Accuracy:  0.98824185\n",
      "epoch :  995 - cost:  0.32776615 - MSE:  0.011105659611471372 - train Accuracy:  0.9882343\n",
      "epoch :  996 - cost:  0.32776377 - MSE:  0.011101224848807245 - train Accuracy:  0.9882318\n",
      "epoch :  997 - cost:  0.32776502 - MSE:  0.011109488327050688 - train Accuracy:  0.9882191\n",
      "epoch :  998 - cost:  0.32775784 - MSE:  0.01110919424747464 - train Accuracy:  0.9882368\n",
      "epoch :  999 - cost:  0.32775575 - MSE:  0.011111972421817738 - train Accuracy:  0.9882292\n",
      "Model saved in file: model\n"
     ]
    }
   ],
   "source": [
    "#calculate the cost and accuracy for each epoch\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x:train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x:train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #print \n",
    "    \n",
    "    pred_y = sess.run(y, feed_dict ={x:test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print(\"epoch : \", epoch, \"-\", \"cost: \", cost, \"- MSE: \", mse_, \"- train Accuracy: \", accuracy)\n",
    "    \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9def82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Accuracy Graph\n",
    "plt.plot(accuracy_history)\n",
    "plt.title(\"Accuracy Graph\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ca0212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Cost Graph\n",
    "plt.plot(cost_history)\n",
    "plt.title(\"Cost Graph\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d568a1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot mse Graph\n",
    "plt.plot(mse_history)\n",
    "plt.title(\"mse Graph\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cff4397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:  0.98789525\n"
     ]
    }
   ],
   "source": [
    "#print final accuracy\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print (\"test accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "            \n",
    "                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f7dfe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mse: -0.0068\n"
     ]
    }
   ],
   "source": [
    "#print the final mean sq error\n",
    "pred_y = sess.run(y, feed_dict={x:test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y) - test_y)                              \n",
    "print (\"Mse: %.4f\" % sess.run(mse)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "248181c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00318244, 0.9968176 ],\n",
       "       [0.00288173, 0.9971182 ],\n",
       "       [0.97460115, 0.02539891],\n",
       "       ...,\n",
       "       [0.00318244, 0.9968176 ],\n",
       "       [0.00285202, 0.997148  ],\n",
       "       [0.00318244, 0.9968176 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "722bd286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 9., ..., 0., 0., 1.],\n",
       "       [0., 2., 9., ..., 0., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 2., 9., ..., 0., 0., 1.],\n",
       "       [0., 2., 9., ..., 0., 0., 1.],\n",
       "       [0., 2., 9., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd73007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeJUlEQVR4nO3df5BdZZ3n8fenf+R3SDrQxJBEEp0MkEEMbE9G1ylr3KwIOGPEKS2oGmQpLKTKWLhr1ZJh9g93rZpiKNB1BsosakacUVkdYYxWZpBinGGtdSUNBvIDIiGJ0CSSxijhR0j3vfe7f5zTycnlJn2a9O37dN/Pq+rWPec5z3Pu89x0zvc8zzn3PIoIzMys/XS0ugJmZtYaDgBmZm3KAcDMrE05AJiZtSkHADOzNtXV6gqMxVlnnRXLli1rdTXMzCaVRx999MWI6K1Pn1QBYNmyZfT397e6GmZmk4qkXzZK9xCQmVmbcgAwM2tTDgBmZm3KAcDMrE05AJiZtSkHADOzNuUAYGbWpibV7wBs/A1Xa/y/Pb/mosXz6eoUXZ2iWgsqtSACIvJ3oBaFNMjTs8eJj+TJlrN8HFvP34nCcpbv+PKx3HV5suW3LpjF4MtHOfz6cKF+2UYJQPk7CJCUv4PybefMn8n/eXqQ7s4O5s/sphZZm2p5e4jjdRxpz8hndCjbR/E9e2WfNfJ+rP0N2n6sUXVtK36Hx7+F8tQgLYBaLY5/bt3+R/u84mPi37it/pPK7rO4bSzlTv5tlN5nfdsLy7VacOi1IWrxxn+HemrwZY/1ifrF/1Nv+Ps4hQ+vWsyys2aP7cNG4QCQuAd3vsB3+5+jlh+havkBeOTgBccPzMcP0Nkf1Ejeai341eHXWTB7OpVqjSPDVY4MVTkyXOW1oWpL21fWW86Ywa8Ov97qapi1zKql8x0A2kFE8PpwjVoE/+vfnuGpX73M0gWz6CicgY6c4Z5wBpqf6XZ0QIc6jp2pArxl3gyGq8H0rg5mdncyY1ons7o7mTmtE4Cujg6md3dQrQVdHaKzQyecRdd/bvHMeuSkaCSNujPx48t1+TjxjKq476xMtv+v/999PLL3EABf+Ng7mTezm84OHWvbCT2PPOGE3kbAX//L0zwx8BK/v6yH9ZefT6UadHRk3xuFdjRq38g+RnoKWaDNg3DtxKBc7IVQaEexrce/LzVIK/4lNDq3r3fyM8eRXsoJe6zbpQqf0ejs9s2UO+HflJN/fv3Hnartpy6nU2wrV5cFs6fR2XHq76JMz6D+M06Vv/j3drLPbDYHgBY78NIRXnx5iIefHqR/3yFeOVrh+d8cYf9Lx892P/7uc/kfay9sYS1ba/vzL/HI3kP0zp3OlRcvPuE/fFlvPXMWG/7tGf7yyncwo7uzCbU0m3wcAFpo74uv8r7b//XY+llzpvO7C+fwjiXz+GjfUmZP76RD4o8vOqd1lUzARy5Zwm+PDPOnlyx5Uwd/gN9dOJcvfGzV+FbMbJJzAGihPYOvAPDfPngB71g8j75lC07ohlrmd86ew19e+Y5WV8NsynEAaKFH9mXj2h+8aBGL5s1scW3MrN34dwAtdP9jzwPQO2d6i2tiZu3IAaCFahH8wfIFdHX6n8HMJp6PPC10dLjGBYvOaHU1zKxNOQC0SLUWvHy0wryZ3a2uipm1KQeAFnnl9QoAZzgAmFmLlAoAki6TtEvSbknrG2zvkXS/pCckPSLpwjz9PElbC6/Dkj6Tb/ucpOcL264Y15YlbvCVowD0zHIAMLPWGPU2UEmdwF3A+4EBYIukTRGxs5DtFmBrRFwp6fw8/5qI2AWsKuzneeD+QrkvRsTt49KSSWbvi68C2UPOzMxaoUwPYDWwOyL2RMQQcC+wti7PSuAhgIh4ClgmaWFdnjXAMxHRcHb6dvKvuw6y7luP0d0plo/zw53MzMoqEwAWA88V1gfytKLHgY8ASFoNnAssqctzFfDturR1+bDRRkk9jT5c0g2S+iX1Dw4Olqhu+r72k71I8HfX/wFn+jcAZtYiZQLAyR43XnQr0CNpK/Bp4OdA5dgOpGnAh4DvFsp8GXg72RDRAeCORh8eEXdHRF9E9PX29paobvqeOfgKl1+4iHe97cxWV8XM2liZR0EMAEsL60uA/cUMEXEYuA5A2dO69uavEZcDj0XEC4Uyx5YlfQX44VgrP1kdfr3CmbOntboaZtbmyvQAtgArJC3Pz+SvAjYVM0ian28D+ATwcB4URlxN3fCPpEWF1SuB7WOt/GQ1XK3R2emHvplZa43aA4iIiqR1wANAJ7AxInZIujHfvgG4APiGpCqwE7h+pLykWWR3EH2ybte3SVpFNpy0r8H2KataC7o7/BMMM2utUk8DjYjNwOa6tA2F5Z8CK05S9jXgDYPdEXHNmGo6RURk89n6sc9m1mo+DZ1g1WxyX7ocAMysxRwAJlhlJAD4CaBm1mI+Ck2winsAZpYIB4AJVq1mAcDXAMys1RwAJlilVgOg27eBmlmLOQBMsJEhoE7fBmpmLeaj0AQ7fhHYPQAzay0HgAlWqWZDQL4IbGat5gAwwY4PATkAmFlrOQBMsJEfgnX7dwBm1mI+Ck2w4XwIyD0AM2s1B4AJ5kdBmFkqHAAmmB8FYWap8FFogm3ams2lM73LX72ZtZaPQhPsgR2/4nfOnsPvL1vQ6qqYWZtzAJhAEcGhV4dYc/7ZvghsZi3nADCBjgxXOVqp0eP5gM0sAQ4AE+jQq0MALJjlAGBmrVcqAEi6TNIuSbslrW+wvUfS/ZKekPSIpAsL2/ZJ2iZpq6T+QvoCSQ9Kejp/7xmfJqXryFAVgFnTO1tcEzOzEgFAUidwF3A5sBK4WtLKumy3AFsj4iLg48CX6ra/LyJWRURfIW098FBErAAeytentGr4NwBmlo4yPYDVwO6I2BMRQ8C9wNq6PCvJDuJExFPAMkkLR9nvWuCefPke4MNlKz1ZVfLJYDrkAGBmrVcmACwGniusD+RpRY8DHwGQtBo4F1iSbwvgR5IelXRDoczCiDgAkL+f3ejDJd0gqV9S/+DgYInqpqvqR0GbWULKBIBGR6uoW78V6JG0Ffg08HOgkm97T0RcQjaE9ClJ7x1LBSPi7ojoi4i+3t7esRRNzsgQkHsAZpaCrhJ5BoClhfUlwP5ihog4DFwHIEnA3vxFROzP3w9Kup9sSOlh4AVJiyLigKRFwMHTbEvyjj8HyDdfmVnrlTkSbQFWSFouaRpwFbCpmEHS/HwbwCeAhyPisKTZkubmeWYDlwLb83ybgGvz5WuB759eU9JX9VwAZpaQUXsAEVGRtA54AOgENkbEDkk35ts3ABcA35BUBXYC1+fFFwL3Z50CuoBvRcQ/59tuBb4j6XrgWeCj49esNDkAmFlKygwBERGbgc11aRsKyz8FVjQotwd450n2+WtgzVgqO9l5NjAzS4kHoydQzQHAzBLiADCBKp4MxswS4gAwgUauAfg2UDNLgQPABPIPwcwsJQ4AE6hS84TwZpYOB4AJVMt/CdzpISAzS4ADwAQaeRicewBmlgIHgAnkH4KZWUocACaQ5wMws5Q4AEygY7eBOgCYWQIcACZQ1T8EM7OEOABMIF8DMLOUOABMoIMvHwU8H4CZpcFHognywuHX2fiTvVy6ciEzp3W2ujpmZg4AE+XhXwxSqQWfvfS8VlfFzAxwAJgwL74yBMDSBTNbXBMzs4wDwAT5zWtDTO/qYGa3h3/MLA0OABNguFrjWz97ljNmdiM/B8jMElEqAEi6TNIuSbslrW+wvUfS/ZKekPSIpAvz9KWSfizpSUk7JN1UKPM5Sc9L2pq/rhi/ZqXlJ7tf5JWjFXrnTG91VczMjhl1TmBJncBdwPuBAWCLpE0RsbOQ7RZga0RcKen8PP8aoAJ8NiIekzQXeFTSg4WyX4yI28ezQSk6fGQYgDs+1nB6ZDOzlijTA1gN7I6IPRExBNwLrK3LsxJ4CCAingKWSVoYEQci4rE8/WXgSWDxuNV+knhtqApAz6xpLa6JmdlxZQLAYuC5wvoAbzyIPw58BEDSauBcYEkxg6RlwMXAzwrJ6/Jho42Sehp9uKQbJPVL6h8cHCxR3fS8erQCwOzpvgBsZukoEwAaXbWMuvVbgR5JW4FPAz8nG/7JdiDNAb4HfCYiDufJXwbeDqwCDgB3NPrwiLg7Ivoioq+3t7dEddPz6tGsBzBr2qgjbmZmE6bMEWkAWFpYXwLsL2bID+rXASi7zWVv/kJSN9nB/5sRcV+hzAsjy5K+AvzwzTUhfa8NVZjR3eFnAJlZUsr0ALYAKyQtlzQNuArYVMwgaX6+DeATwMMRcTgPBl8DnoyIL9SVWVRYvRLY/mYbkbrfvDbEnOk++zeztIx6VIqIiqR1wANAJ7AxInZIujHfvgG4APiGpCqwE7g+L/4e4BpgWz48BHBLRGwGbpO0imw4aR/wyfFqVGoe/eVvuGjJ/FZXw8zsBKVOS/MD9ua6tA2F5Z8CKxqU+wmNryEQEdeMqaaT2G9fG+Zdb5vR6mqYmZ3AvwSeAMPVGt2d/qrNLC0+Kk2ASi3o7vQFYDNLiwPABBiu1uhyD8DMEuOjUpNFBMPVoNu3gJpZYhwAmmxkHmBfAzCz1Pio1GSVPAB4CMjMUuOjUpMNVWsAvghsZslxAGiySjXvAfgagJklxgGgySojPYAuf9VmlhYflZpseOQicIe/ajNLi49KTTZcyXoAXb4GYGaJcQBoskptJAD4qzaztPio1GTD1ZEhIPcAzCwtDgBN1r/vEABzZ3S3uCZmZidyAGiyxwde4owZXbz77We2uipmZidwAGiyPYOv8HvnzPN0kGaWHAeAJjv48lEWzfNkMGaWnlIBQNJlknZJ2i1pfYPtPZLul/SEpEckXThaWUkLJD0o6en8vWd8mpSW3742zPxZ00bPaGY2wUYNAJI6gbuAy4GVwNWSVtZluwXYGhEXAR8HvlSi7HrgoYhYATyUr08pQ5Uarxyt0DPLF4DNLD1legCrgd0RsScihoB7gbV1eVaSHcSJiKeAZZIWjlJ2LXBPvnwP8OHTaUiKfntkCID5s90DMLP0lAkAi4HnCusDeVrR48BHACStBs4FloxSdmFEHADI388ea+VT9+rRKgBzpne2uCZmZm9UJgA0un0l6tZvBXokbQU+DfwcqJQse+oPl26Q1C+pf3BwcCxFW+714SwAzOx2ADCz9HSVyDMALC2sLwH2FzNExGHgOgBJAvbmr1mnKPuCpEURcUDSIuBgow+PiLuBuwH6+vrGFDxa7UgeAKY7AJhZgsr0ALYAKyQtlzQNuArYVMwgaX6+DeATwMN5UDhV2U3AtfnytcD3T68p6RnpAczocgAws/SM2gOIiIqkdcADQCewMSJ2SLox374BuAD4hqQqsBO4/lRl813fCnxH0vXAs8BHx7dprXdsCGiaA4CZpafMEBARsRnYXJe2obD8U2BF2bJ5+q+BNWOp7GTz+nD2JNAZ3f69nZmlx0emJjoy5IvAZpYuB4Amer2SXwNwADCzBDkANNHIbGDdngzGzBLkI1MTVfL5gD0dpJmlyAGgiaojAcCPgjazBDkANNFID8BzAZhZihwAmuh4D8Bfs5mlx0emJhrpAbgDYGYpcgBoomqtRleHyB6PZGaWFgeAJqrUwuP/ZpYsB4AmqlbDdwCZWbIcAJrIPQAzS5kDQBNVa0GXfwVsZony0amJ3AMws5Q5ADTRyF1AZmYpcgBoIvcAzCxlDgBNVK35LiAzS5cDQBO5B2BmKSsVACRdJmmXpN2S1jfYPk/SDyQ9LmmHpOvy9PMkbS28Dkv6TL7tc5KeL2y7YlxbloDsdwCOsWaWplHnBJbUCdwFvB8YALZI2hQROwvZPgXsjIg/kdQL7JL0zYjYBawq7Od54P5CuS9GxO3j05T0uAdgZikrc3q6GtgdEXsiYgi4F1hblyeAucoeejMHOARU6vKsAZ6JiF+eZp0njWqt5slgzCxZZQLAYuC5wvpAnlZ0J3ABsB/YBtwUEbW6PFcB365LWyfpCUkbJfU0+nBJN0jql9Q/ODhYorrpqNSCDj8IzswSVSYANDqCRd36B4CtwDlkQz53Sjrj2A6kacCHgO8WynwZeHue/wBwR6MPj4i7I6IvIvp6e3tLVDcdEX4UtJmlq0wAGACWFtaXkJ3pF10H3BeZ3cBe4PzC9suBxyLihZGEiHghIqp5T+ErZENNU0rgHoCZpatMANgCrJC0PD+TvwrYVJfnWbIxfiQtBM4D9hS2X03d8I+kRYXVK4HtY6t6+mo18PHfzFI16l1AEVGRtA54AOgENkbEDkk35ts3AJ8Hvi5pG9mQ0c0R8SKApFlkdxB9sm7Xt0laRTactK/B9kkvCNRwBM3MrPVGDQAAEbEZ2FyXtqGwvB+49CRlXwPObJB+zZhqOglFuAdgZunyr5SayAHAzFLmANBEHgIys5Q5ADRRBPhJEGaWKh+emqgW7gGYWbocAJoo8DUAM0uXA0ATZReBHQHMLE0OAE0UER4AMrNkOQA0kYeAzCxlDgBNlD0MzhHAzNLkANBENQ8BmVnCHACayL8ENrOUOQA0UXYNwBHAzNLkANBEvgvIzFLmANBEHgIys5Q5ADSRZwQzs5Q5ADRRzT0AM0uYA0AThR8GZ2YJcwBoIv8S2MxSVioASLpM0i5JuyWtb7B9nqQfSHpc0g5J1xW27ZO0TdJWSf2F9AWSHpT0dP7eMz5NSocfBmdmKRs1AEjqBO4CLgdWAldLWlmX7VPAzoh4J/BHwB2SphW2vy8iVkVEXyFtPfBQRKwAHsrXpxTfBmpmKSvTA1gN7I6IPRExBNwLrK3LE8BcZae7c4BDQGWU/a4F7smX7wE+XLbSk0UAHY4AZpaoMgFgMfBcYX0gTyu6E7gA2A9sA26KiFq+LYAfSXpU0g2FMgsj4gBA/n52ow+XdIOkfkn9g4ODJaqbjlqEh4DMLFllAkCjI1jUrX8A2AqcA6wC7pR0Rr7tPRFxCdkQ0qckvXcsFYyIuyOiLyL6ent7x1K05SIaf3lmZikoEwAGgKWF9SVkZ/pF1wH3RWY3sBc4HyAi9ufvB4H7yYaUAF6QtAggfz/4ZhuRKl8ENrOUlQkAW4AVkpbnF3avAjbV5XkWWAMgaSFwHrBH0mxJc/P02cClwPa8zCbg2nz5WuD7p9OQFEWEbwM1s2R1jZYhIiqS1gEPAJ3AxojYIenGfPsG4PPA1yVtIxv1uDkiXpT0NuD+/Cy4C/hWRPxzvutbge9Iup4sgHx0nNvWcoGHgMwsXaMGAICI2AxsrkvbUFjeT3Z2X19uD/DOk+zz1+S9hqnKM4KZWcr8S+AmqnkIyMwS5gDQRH4UhJmlzAGgiXwXkJmlzAGgifwoCDNLmQNAE3kIyMxS5gDQRBGeEczM0uUA0EQ1PwrCzBLmANBE4YfBmVnCHACayNcAzCxlDgBNlD0N1BHAzNLkANBEfhicmaXMAaCJauEZwcwsXQ4ATRT4IrCZpcsBoImyR0G0uhZmZo05ADSRLwKbWcocAJooGwJqdS3MzBpzAGii8EVgM0uYA0AT1SI8BGRmySoVACRdJmmXpN2S1jfYPk/SDyQ9LmmHpOvy9KWSfizpyTz9pkKZz0l6XtLW/HXF+DUrDf4lsJmlbNQ5gSV1AncB7wcGgC2SNkXEzkK2TwE7I+JPJPUCuyR9E6gAn42IxyTNBR6V9GCh7Bcj4vZxbVFCPCGMmaWsTA9gNbA7IvZExBBwL7C2Lk8Ac5Ud7eYAh4BKRByIiMcAIuJl4Elg8bjVPmERAfhpoGaWrjIBYDHwXGF9gDcexO8ELgD2A9uAmyKiVswgaRlwMfCzQvI6SU9I2iipp9GHS7pBUr+k/sHBwRLVTUN+/PcQkJklq0wAaHQIi7r1DwBbgXOAVcCdks44tgNpDvA94DMRcThP/jLw9jz/AeCORh8eEXdHRF9E9PX29paobhpGviBPCGNmqSoTAAaApYX1JWRn+kXXAfdFZjewFzgfQFI32cH/mxFx30iBiHghIqp5T+ErZENNU0bNQ0BmlrgyAWALsELScknTgKuATXV5ngXWAEhaCJwH7MmvCXwNeDIivlAsIGlRYfVKYPuba0KaPARkZqkb9S6giKhIWgc8AHQCGyNih6Qb8+0bgM8DX5e0jeyk9+aIeFHSHwLXANskbc13eUtEbAZuk7SKbLRkH/DJcW1Zi0U+COS7gMwsVaMGAID8gL25Lm1DYXk/cGmDcj/hJKMgEXHNmGo6yVRrWQDo9E+BzSxR/iVwkwxXswDQ5QBgZolyAGiSSjW7C7a701+xmaXJR6cm8RCQmaXOAaBJhvMA0N3pAGBmaXIAaJKRIaCuDn/FZpYmH52a5NhFYPcAzCxRDgBNUqn5IrCZpc1HpyapVH0R2MzS5gDQJBVfBDazxDkANIkvAptZ6nx0ahJfBDaz1DkANIkvAptZ6nx0ahJfBDaz1DkANMnwyLOAfA3AzBLlo1OTHBmuAr4GYGbpcgBogojgjh/9grPmTGNJz8xWV8fMrKFSE8JMdn/z0NNserx+GuPmqUbw7KHX+Ks/fQdzZ3RP2OeamY1FqQAg6TLgS2RTQn41Im6t2z4P+Hvgrfk+b4+Ivz1VWUkLgP8NLCObEvJjEfGb02/SG/XOnc6KhXOaseuTunhpD5f93qLRM5qZtYhiZPbyk2WQOoFfAO8HBsgmib86InYW8twCzIuImyX1AruAtwDVk5WVdBtwKCJulbQe6ImIm09Vl76+vujv73+TTTUza0+SHo2Ivvr0MtcAVgO7I2JPRAwB9wJr6/IEMFfZDOhzgENAZZSya4F78uV7gA+PrUlmZnY6ygSAxcBzhfWBPK3oTuACYD+wDbgpImqjlF0YEQcA8vezx1x7MzN708oEgEb3MdaPG30A2AqcA6wC7pR0Rsmyp/5w6QZJ/ZL6BwcHx1LUzMxOoUwAGACWFtaXkJ3pF10H3BeZ3cBe4PxRyr4gaRFA/n6w0YdHxN0R0RcRfb29vSWqa2ZmZZQJAFuAFZKWS5oGXAVsqsvzLLAGQNJC4DxgzyhlNwHX5svXAt8/nYaYmdnYjHobaERUJK0DHiC7lXNjROyQdGO+fQPweeDrkraRDfvcHBEvAjQqm+/6VuA7kq4nCyAfHd+mmZnZqYx6G2hKfBuomdnYnc5toGZmNgVNqh6ApEHgl2+y+FnAi+NYncnAbW4PbnN7OJ02nxsRb7iLZlIFgNMhqb9RF2gqc5vbg9vcHprRZg8BmZm1KQcAM7M21U4B4O5WV6AF3Ob24Da3h3Fvc9tcAzAzsxO1Uw/AzMwKHADMzNpUWwQASZdJ2iVpdz75zKQnaamkH0t6UtIOSTfl6QskPSjp6fy9p1Dmz/PvYJekD7Su9qdHUqekn0v6Yb4+pdssab6kf5D0VP7v/e42aPN/zv+ut0v6tqQZU63NkjZKOihpeyFtzG2U9O8kbcu3/XU+L0s5ETGlX2TPIHoGeBswDXgcWNnqeo1DuxYBl+TLc8lmXlsJ3Aasz9PXA3+VL6/M2z4dWJ5/J52tbsebbPt/Ab4F/DBfn9JtJpsw6RP58jRg/lRuM9mcIXuBmfn6d4D/NNXaDLwXuATYXkgbcxuBR4B3kz2H7Z+Ay8vWoR16AGVmNJt0IuJARDyWL78MPEn2H+dkM62tBe6NiKMRsRfYTfbdTCqSlgAfBL5aSJ6ybc7n1Xgv8DWAiBiKiN8yhduc6wJmSuoCZpE9Rn5KtTkiHiabPbFoTG3MH6V/RkT8NLJo8A3GMLtiOwSAMjOaTWqSlgEXAz/j5DOtTZXv4X8C/xWoFdKmcpvfBgwCf5sPe31V0mymcJsj4nngdrKnBB8AXoqIHzGF21ww1jYuzpfr00tphwBw2rOSpUzSHOB7wGci4vCpsjZIm1Tfg6Q/Bg5GxKNlizRIm1RtJjsTvgT4ckRcDLxKNjRwMpO+zfm491qyoY5zgNmS/uxURRqkTao2l3CyNp5W29shAJSZ0WxSktRNdvD/ZkTclyefbKa1qfA9vAf4kKR9ZEN5/0HS3zO12zwADETEz/L1fyALCFO5zf8R2BsRgxExDNwH/HumdptHjLWNA/lyfXop7RAAysxoNunkV/q/BjwZEV8obDrZTGubgKskTZe0HFhBdvFo0oiIP4+IJRGxjOzf8V8i4s+Y2m3+FfCcpPPypDXATqZwm8mGft4laVb+d76G7BrXVG7ziDG1MR8melnSu/Lv6uOMZXbFVl8Jn6Cr7VeQ3SXzDPAXra7POLXpD8m6ek8AW/PXFcCZwEPA0/n7gkKZv8i/g12M4U6BFF/AH3H8LqAp3WZgFdCf/1v/I9DTBm3+78BTwHbg78jufplSbQa+TXaNY5jsTP76N9NGoC//np4B7iR/wkOZlx8FYWbWptphCMjMzBpwADAza1MOAGZmbcoBwMysTTkAmJm1KQcAM7M25QBgZtam/j9KGALME8BuhQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.001\n",
      "MAE: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Plot mse and accuracy graph\n",
    "plt.plot(mse_history, 'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()\n",
    "\n",
    "#Once the model is trained, we can apply cross validation\n",
    "\n",
    "#Define KFold\n",
    "kf = KFold(n_splits=2)\n",
    "\n",
    "#Define the KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#loop through the KFold splits\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "    \n",
    "    #fit the model on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    #predict on the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    #calculate the mean absolute error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print('MAE: %.3f' % mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11cde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756177ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
